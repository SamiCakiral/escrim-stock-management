{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamiCakiral/escrim-stock-management/blob/main/R%26D_IMT_Mines_Al%C3%A8s_YOLO_XSENS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP0yAiIAJm_c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install super-gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX08s9XVTM_2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "from imutils import paths\n",
        "from IPython.display import YouTubeVideo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "may0acXMJnUS"
      },
      "source": [
        "# Instantiate the model!\n",
        "\n",
        "Start by instantiating a pretrained model. YOLO-NAS-Pose comes in three flavors: `yolo_nas_pose_s`, `yolo_nas_pose_m`, and `yolo_nas_pose_l`.\n",
        "\n",
        "You'll use `yolo_nas_pose_l` throughout this notebook. Because you should always go big, or go home.\n",
        "\n",
        "It's a good life philosophy.\n",
        "\n",
        "**Note:** I am using a High-RAM instance of a T4 when running this notebook. If you don't have access to the High-RAM instance, I suggest trying the medium or small versions of the model. If you think you have enough RAM, but find this taking too much memory for your liking, set `fuse_model=False` in the `predict` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbDPi-8VNbFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7104e60-da11-4b02-ad17-e47997af7b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-22 19:45:55] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is logged into /root/sg_logs/console.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-22 19:46:07] INFO - utils.py - NumExpr defaulting to 2 threads.\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: boto3 required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: deprecated required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: coverage required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: sphinx-rtd-theme required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: torchmetrics required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: hydra-core required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: omegaconf required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnxruntime required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnx required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: pillow==9.4.0 does not satisfy requirement pillow>=10.2.0\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: einops required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: treelib required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: stringcase required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: rapidfuzz required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: json-tricks required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnxsim required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: data-gradients required but not found\u001b[0m\n",
            "[2024-04-22 19:46:12] WARNING - checkpoint_utils.py - :warning: The pre-trained models provided by SuperGradients may have their own licenses or terms and conditions derived from the dataset used for pre-training.\n",
            " It is your responsibility to determine whether you have permission to use the models for your use case.\n",
            " The model you have requested was pre-trained on the coco_pose dataset, published under the following terms: https://cocodataset.org/#termsofuse\n",
            "[2024-04-22 19:46:12] INFO - checkpoint_utils.py - License Notification: YOLO-NAS-POSE pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
            "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS-POSE.md\n",
            "By downloading the pre-trained weight files you agree to comply with these terms.\n",
            "Downloading: \"https://sghub.deci.ai/models/yolo_nas_pose_l_coco_pose.pth\" to /root/.cache/torch/hub/checkpoints/yolo_nas_pose_l_coco_pose.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 304M/304M [00:01<00:00, 227MB/s]\n",
            "[2024-04-22 19:46:14] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_pose_l\n"
          ]
        }
      ],
      "source": [
        "from super_gradients.training import models\n",
        "from super_gradients.common.object_names import Models\n",
        "\n",
        "yolo_nas_pose = models.get(\"yolo_nas_pose_l\", pretrained_weights=\"coco_pose\").cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yOwWRkEOXxG"
      },
      "source": [
        "## üñºÔ∏è  Predicting is a one-liner: `yolo_nas_pose.to(device).predict(input_file)`\n",
        "\n",
        "Once the model has been instantiated all you have to do is call the `predict` method. The `predict()` method is built to handle multiple data formats and types.\n",
        "\n",
        "Here is the full list of what `predict()` method can handle:\n",
        "\n",
        "| Argument Semantics                 | Argument Type      | Supported layout                  | Example                                                                                        | Notes                                                                                            |\n",
        "|------------------------------------|--------------------|-----------------------------------|------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
        "| Path to local image                | `str`              | -                                 | `predict(\"path/to/image.jpg\")`                                                                 | All common image extensions are supported.                                                       |\n",
        "| Path to images directory           | `str`              | -                                 | `predict(\"path/to/images/directory\")`                                                          |                                                                                                  |\n",
        "| Path to local video                | `str`              | -                                 | `predict(\"path/to/video.mp4\")`                                                                 | All common video extensions are supported.                                                       |\n",
        "| URL to remote image                | `str`              | -                                 | `predict(\"https://example.com/image.jpg\")`                                                     |                                                                                                  |\n",
        "| 3-dimensional Numpy image          | `np.ndarray`       | `[H, W, C]`                       | `predict(np.zeros((480, 640, 3), dtype=np.uint8))`                                             | Channels last, RGB channel order for 3-channel images                                            |\n",
        "| 4-dimensional Numpy image          | `np.ndarray`       | `[N, H, W, C]` or `[N, C, H, W]`  | `predict(np.zeros((480, 640, 3), dtype=np.uint8))`                                             | Tensor layout (NHWC or NCHW) is inferred w.r.t to number of input channels of underlying model   |\n",
        "| List of 3-dimensional numpy arrays | `List[np.ndarray]` | `[H1, W1, C]`, `[H2, W2, C]`, ... | `predict([np.zeros((480, 640, 3), dtype=np.uint8), np.zeros((384, 512, 3), dtype=np.uint8) ])` | Images may vary in size, but should have same number of channels                                 |\n",
        "| 3-dimensional Torch Tensor         | `torch.Tensor`     | `[H, W, C]` or `[C, H, W]`        | `predict(torch.zeros((480, 640, 3), dtype=torch.uint8))`                                       | Tensor layout (HWC or CHW) is inferred w.r.t to number of input channels of underlying model     |\n",
        "| 4-dimensional Torch Tensor         | `torch.Tensor`     | `[N, H, W, C]` or `[N, C, H, W]`  | `predict(torch.zeros((4, 480, 640, 3), dtype=torch.uint8))`                                    | Tensor layout (NHWC or NCHW) is inferred w.r.t to number of input channels of underlying model   |\n",
        "\n",
        "**Important note** - When using batched input (4-dimensional `np.ndarray` or `torch.Tensor`) formats, **normalization and size preprocessing will be applied to these inputs**.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### For more details about predicting using YOLO-NAS-Pose, check out the [docs](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/ModelPredictions.md)\n",
        "\n",
        "### Let's wrap the predict method in a function just for this notebook. But really it's just one line to predict! And this is it: `yolo_nas_pose.to(device).predict(input_file)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hNHxSUs5E9M"
      },
      "outputs": [],
      "source": [
        "# @title Run this cell for prediction function\n",
        "def make_prediction(input_file, action, confidence=0.55):\n",
        "    \"\"\"\n",
        "    Make a prediction using the fixed model and device, and either show or save the result.\n",
        "\n",
        "    Args:\n",
        "    - input_file (str): Path to the input file.\n",
        "    - action (str): Either 'show' or 'save'.\n",
        "    - confidence (float, optional): Confidence threshold. Defaults to 0.75.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "\n",
        "    Raises:\n",
        "    - ValueError: If the action is not 'show' or 'save'.\n",
        "    \"\"\"\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    if action == \"show\":\n",
        "        yolo_nas_pose.to(device).predict(input_file, conf=confidence).show()\n",
        "    elif action == \"save\":\n",
        "        output_file = pathlib.Path(input_file).stem + \"-detections\" + pathlib.Path(input_file).suffix\n",
        "        yolo_nas_pose.to(device).predict(input_file, conf=confidence).save(output_file)\n",
        "        print(f\"Prediction saved to {output_file}\")\n",
        "    else:\n",
        "        raise ValueError(\"Action must be either 'show' or 'save'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE7gUJA4tS0k"
      },
      "source": [
        "# üìΩÔ∏è Inference on video"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Videos\n",
        "\n",
        "Code pour charger toute les vid√©os de test"
      ],
      "metadata": {
        "id": "tSZ2haevPDu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# URL du fichier ZIP sur Google Drive\n",
        "url = 'https://drive.google.com/uc?id=1-k23dMqskWcYF4KAoMA0yql5kO-1LQRk'\n",
        "https://drive.google.com/file/d/18stBvPNgiNPPYHZGjuaQq2ym7UZ798Fo/view?usp=share_link\n",
        "output_zip_path = '/content/video_archive.zip'\n",
        "\n",
        "# Dossier cible pour extraire le contenu du fichier ZIP\n",
        "extract_to_folder = '/content/video'\n",
        "\n",
        "# Cr√©ez le dossier s'il n'existe pas\n",
        "if not os.path.exists(extract_to_folder):\n",
        "    os.makedirs(extract_to_folder)\n",
        "\n",
        "# T√©l√©chargez le fichier ZIP\n",
        "gdown.download(url, output_zip_path, quiet=False)\n",
        "\n",
        "# D√©compressez le fichier ZIP\n",
        "with zipfile.ZipFile(output_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_folder)\n",
        "\n",
        "# Supprimez le fichier ZIP si vous n'en avez plus besoin\n",
        "os.remove(output_zip_path)\n",
        "\n",
        "print(f'Les vid√©os ont √©t√© extraites dans {extract_to_folder}')\n",
        "\n",
        "url ='https://drive.google.com/uc?id=1hUFaYw6RR2couxLqBJ1tQm0mp_1_Qj-k'\n",
        "output = 'xsensData.xlsx'  # Remplacez par le nom que vous souhaitez donner au fichier t√©l√©charg√©\n",
        "\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "-uOay6sOPDNr",
        "outputId": "f197ceff-7762-4080-bcf4-c36b62ebfcf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-k23dMqskWcYF4KAoMA0yql5kO-1LQRk\n",
            "From (redirected): https://drive.google.com/uc?id=1-k23dMqskWcYF4KAoMA0yql5kO-1LQRk&confirm=t&uuid=476af17c-6c74-437f-a66e-c1dffe0b5c5e\n",
            "To: /content/video_archive.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.91G/1.91G [00:21<00:00, 88.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les vid√©os ont √©t√© extraites dans /content/video\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hUFaYw6RR2couxLqBJ1tQm0mp_1_Qj-k\n",
            "To: /content/xsensData.xlsx\n",
            "\r  0%|          | 0.00/44.1M [00:00<?, ?B/s]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xsensData.xlsx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# URL du fichier ZIP sur Google Drive\n",
        "url = 'https://drive.google.com/uc?id=18stBvPNgiNPPYHZGjuaQq2ym7UZ798Fo'\n",
        "\n",
        "output_zip_path = '/content/csv.zip'\n",
        "\n",
        "# Dossier cible pour extraire le contenu du fichier ZIP\n",
        "extract_to_folder = '/content/csv'\n",
        "\n",
        "# Cr√©ez le dossier s'il n'existe pas\n",
        "if not os.path.exists(extract_to_folder):\n",
        "    os.makedirs(extract_to_folder)\n",
        "\n",
        "# T√©l√©chargez le fichier ZIP\n",
        "gdown.download(url, output_zip_path, quiet=False)\n",
        "\n",
        "# D√©compressez le fichier ZIP\n",
        "with zipfile.ZipFile(output_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_folder)\n",
        "\n",
        "# Supprimez le fichier ZIP si vous n'en avez plus besoin\n",
        "os.remove(output_zip_path)\n",
        "\n",
        "print(f'Les fichiers CSV ont √©t√© extraits dans {extract_to_folder}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "f197ceff-7762-4080-bcf4-c36b62ebfcf1",
        "id": "pPXrlCkCMNZW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-k23dMqskWcYF4KAoMA0yql5kO-1LQRk\n",
            "From (redirected): https://drive.google.com/uc?id=1-k23dMqskWcYF4KAoMA0yql5kO-1LQRk&confirm=t&uuid=476af17c-6c74-437f-a66e-c1dffe0b5c5e\n",
            "To: /content/video_archive.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.91G/1.91G [00:21<00:00, 88.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les vid√©os ont √©t√© extraites dans /content/video\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hUFaYw6RR2couxLqBJ1tQm0mp_1_Qj-k\n",
            "To: /content/xsensData.xlsx\n",
            "\r  0%|          | 0.00/44.1M [00:00<?, ?B/s]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xsensData.xlsx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction pour le calcul des angles et du score + Squelette"
      ],
      "metadata": {
        "id": "--vN3i0UUivy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour analyser les poses humaines √† partir de vid√©os ou d'images en utilisant le mod√®le **YoloNAS**, qui est entra√Æn√© sur le dataset **COCO**, nous avons d√©velopp√© un protocole sp√©cifique pour extraire, calculer et analyser les angles form√©s par diff√©rents points du squelette humain. Voici une explication claire du processus en plusieurs √©tapes :\n",
        "\n",
        "### 1. **Extraction des Keypoints**\n",
        "\n",
        "Chaque pr√©diction de pose fournie par YoloNAS renferme un ensemble de points cl√©s (**keypoints**) correspondant aux articulations du corps humain, dispos√©s selon la norme COCO. Ces keypoints incluent des parties cruciales du corps telles que les √©paules, les coudes, les poignets, les hanches, les genoux et les chevilles, ainsi que le nez, les yeux et les oreilles, offrant une repr√©sentation compl√®te du squelette humain.\n",
        "\n",
        "### 2. **D√©finition des Angles d'Int√©r√™t**\n",
        "\n",
        "Pour proc√©der √† l'analyse, nous d√©finissons d'abord les angles d'int√©r√™t en fonction des connexions naturelles entre les articulations. Par exemple, l'angle du coude gauche est form√© par les keypoints de l'√©paule gauche, du coude gauche et du poignet gauche. Cette approche est appliqu√©e √† diverses parties du corps pour extraire des informations pertinentes sur la posture.\n",
        "\n",
        "### 3. **Calcul des Angles**\n",
        "\n",
        "La fonction `calculate_angle` calcule l'angle en degr√©s au point B (l'articulation centrale, par exemple, le coude ou le genou) en utilisant la loi des cosinus. Cette loi math√©matique permet de d√©terminer l'angle form√© entre deux segments de ligne (AB et BC) √† partir des longueurs des c√¥t√©s d'un triangle et du produit scalaire des vecteurs. Ce calcul est essentiel pour quantifier la position et le mouvement des diff√©rentes parties du corps.\n",
        "\n",
        "### 4. **Extraction et Pr√©paration des Donn√©es**\n",
        "\n",
        "Nous avons d√©velopp√© la fonction `extract_keypoints_for_angles` pour extraire sp√©cifiquement les coordonn√©es n√©cessaires au calcul des angles d'int√©r√™t √† partir des pr√©dictions de pose. Cette fonction filtre les poses en fonction d'un seuil de confiance pour assurer la fiabilit√© des donn√©es extraites.\n",
        "\n",
        "### 5. **Stockage et Analyse des R√©sultats**\n",
        "\n",
        "Les angles calcul√©s pour chaque frame d'une vid√©o ou pour chaque image sont ensuite stock√©s dans un DataFrame pandas par la fonction `calculate_and_store_angles`. Ce DataFrame organise les donn√©es de mani√®re √† faciliter l'analyse, avec une ligne par frame et une colonne pour chaque angle calcul√©, permettant ainsi une visualisation claire de l'√©volution des postures dans le temps.\n",
        "\n",
        "### R√©sum√©\n",
        "\n",
        "En somme, ce protocole offre une m√©thode syst√©matique et pr√©cise pour l'analyse des postures humaines en se basant sur les pr√©dictions de pose du mod√®le **YoloNAS** entra√Æn√© sur le dataset **COCO**. Gr√¢ce √† l'extraction minutieuse des keypoints, au calcul rigoureux des angles entre les articulations et √† l'organisation structur√©e des donn√©es r√©sultantes, nous pouvons obtenir des insights d√©taill√©s sur la posture et le mouvement des sujets captur√©s dans les vid√©os ou les images analys√©es.\n"
      ],
      "metadata": {
        "id": "izwnhRg6eNHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Fonctions pour le calcul d'angle\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calculate_angle(A, B, C):\n",
        "    \"\"\"\n",
        "    Calcule l'angle en degr√©s au point B entre les segments form√©s par les points A, B, et C.\n",
        "\n",
        "    Args:\n",
        "    - A, B, C: Coordonn√©es des points (x, y) sous forme de tuples ou listes.\n",
        "\n",
        "    Returns:\n",
        "    - angle_degrees: L'angle en degr√©s au point B.\n",
        "    \"\"\"\n",
        "    BA = np.array(A) - np.array(B)\n",
        "    BC = np.array(C) - np.array(B)\n",
        "    cosine_angle = np.dot(BA, BC) / (np.linalg.norm(BA) * np.linalg.norm(BC))\n",
        "    angle = np.arccos(cosine_angle)\n",
        "    angle_degrees = np.degrees(angle)\n",
        "    return angle_degrees\n",
        "\n",
        "def extract_keypoints_for_angles(image_prediction, confidence=0.55):\n",
        "    \"\"\"\n",
        "    Extrait les coordonn√©es des keypoints pour les poses d√©tect√©es dans une image,\n",
        "    filtr√©es par un seuil de confiance, pour une structure de pose bas√©e sur COCO.\n",
        "\n",
        "    Args:\n",
        "    - image_prediction (ImagePoseEstimationPrediction): Le r√©sultat de la pr√©diction pour une image unique.\n",
        "    - confidence (float, optional): Seuil de confiance pour filtrer les poses. Par d√©faut √† 0.55.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Un dictionnaire contenant les coordonn√©es des keypoints pour les angles d'int√©r√™t.\n",
        "    \"\"\"\n",
        "    # D√©finition bas√©e sur COCO keypoints\n",
        "    skeleton_structure = {\n",
        "        'Bras Gauche': (11, 5, 9),  # Hanche gauche, √âpaule gauche, Poignet gauche\n",
        "        'Bras Droit': (12, 6, 10),  # Hanche droite, √âpaule droite, Poignet droit\n",
        "        'Coude Gauche': (5, 7, 9),  # √âpaule gauche, Coude gauche, Poignet gauche\n",
        "        'Coude Droit': (6, 8, 10),  # √âpaule droite, Coude droit, Poignet droit\n",
        "        'Jambe Gauche': (0, 11, 15),  # Nez (comme substitut pour le buste), Hanche gauche, Cheville gauche\n",
        "        'Jambe Droite': (0, 12, 16),  # Nez (comme substitut pour le buste), Hanche droite, Cheville droite\n",
        "        'Genou Gauche': (11, 13, 15),  # Hanche gauche, Genou gauche, Cheville gauche\n",
        "        'Genou Droit': (12, 14, 16),  # Hanche droite, Genou droit, Cheville droite\n",
        "        'Poignet Gauche': (5, 7, 9),  # √âpaule gauche, Coude gauche, Poignet gauche\n",
        "        'Poignet Droit': (6, 8, 10)   # √âpaule droite, Coude droit, Poignet droit\n",
        "    }\n",
        "\n",
        "\n",
        "    keypoints_coordinates = {}\n",
        "    if image_prediction.prediction.scores.size > 0 and image_prediction.prediction.poses.size > 0:\n",
        "      # Assurez-vous d'extraire les coordonn√©es pour la pose la plus confiante\n",
        "      if image_prediction.prediction.scores[0] > confidence:\n",
        "          pose = image_prediction.prediction.poses[0]  # Prendre la premi√®re pose pour l'exemple\n",
        "\n",
        "          for angle_name, (p1, p2, p3) in skeleton_structure.items():\n",
        "              # Extraire les coordonn√©es (x, y) pour chaque groupe de points\n",
        "              A = (pose[p1][0], pose[p1][1])\n",
        "              B = (pose[p2][0], pose[p2][1])\n",
        "              C = (pose[p3][0], pose[p3][1])\n",
        "\n",
        "              keypoints_coordinates[angle_name] = [A, B, C]\n",
        "\n",
        "    return keypoints_coordinates\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "def calculate_and_store_angles(image_predictions, confidence=0.55):\n",
        "    \"\"\"\n",
        "    Pour chaque pr√©diction d'image, calcule les angles sp√©cifi√©s et stocke les r√©sultats dans un DataFrame\n",
        "    avec une ligne par frame et une colonne pour chaque angle.\n",
        "\n",
        "    Args:\n",
        "    - image_predictions (List[ImagePoseEstimationPrediction]): Liste des pr√©dictions pour chaque image/frame.\n",
        "    - confidence (float): Seuil de confiance pour prendre en compte une pr√©diction.\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame: Un DataFrame contenant les angles calcul√©s pour chaque frame/image, structur√© par frame.\n",
        "    \"\"\"\n",
        "    # Initialisation d'une liste pour stocker les donn√©es de chaque frame/image\n",
        "    angles_data = []\n",
        "\n",
        "    for i, image_prediction in enumerate(image_predictions):\n",
        "        # Dictionnaire pour stocker les angles de la frame courante\n",
        "        frame_angles = {'Frame': i}\n",
        "\n",
        "        # Extraction des coordonn√©es des keypoints pour les angles d'int√©r√™t\n",
        "        keypoints_coordinates = extract_keypoints_for_angles(image_prediction, confidence)\n",
        "\n",
        "        # Calcul des angles pour chaque groupe de keypoints d'int√©r√™t\n",
        "        for angle_name, coords_group in keypoints_coordinates.items():\n",
        "            # Assurez-vous que nous avons exactement trois points (A, B, C)\n",
        "            if len(coords_group) == 3:\n",
        "                A, B, C = coords_group\n",
        "                angle = calculate_angle(A, B, C)\n",
        "                # Ajoutez l'angle calcul√© au dictionnaire de la frame courante\n",
        "                frame_angles[f'Angle {angle_name}'] = angle\n",
        "\n",
        "        # Ajoutez les angles de la frame courante √† la liste des donn√©es\n",
        "        angles_data.append(frame_angles)\n",
        "\n",
        "    # Cr√©ez le DataFrame √† partir de la liste des donn√©es\n",
        "    df = pd.DataFrame(angles_data)\n",
        "\n",
        "    # R√©ordonnez les colonnes pour mettre 'Frame' en premi√®re position si n√©cessaire\n",
        "    cols = ['Frame'] + [col for col in df.columns if col != 'Frame']\n",
        "    df = df[cols]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pathlib\n",
        "\n",
        "def process_single_image(image_prediction, confidence=0.55):\n",
        "    \"\"\"\n",
        "    Process a single image prediction by drawing the detected poses on the image.\n",
        "\n",
        "    Args:\n",
        "    - image_prediction (ImagePoseEstimationPrediction): The prediction result for a single image.\n",
        "    - confidence (float, optional): Confidence threshold. Defaults to 0.55.\n",
        "\n",
        "    Returns:\n",
        "    - np.ndarray: The processed image with drawn poses.\n",
        "    \"\"\"\n",
        "    # Assurez-vous que le seuil de confiance est respect√© pour chaque pr√©diction\n",
        "    filtered_poses = [pose for pose, score in zip(image_prediction.prediction.poses, image_prediction.prediction.scores) if score > confidence]\n",
        "\n",
        "    # Dessinez les poses filtr√©es sur l'image. Vous pouvez adapter les arguments en fonction de vos besoins sp√©cifiques\n",
        "    processed_image = image_prediction.draw(\n",
        "        joint_thickness=2,  # √âpaisseur des joints\n",
        "        keypoint_radius=3,  # Rayon des keypoints\n",
        "        box_thickness=2,    # √âpaisseur des bo√Ætes\n",
        "        show_confidence=True  # Afficher les scores de confiance\n",
        "    )\n",
        "\n",
        "    return processed_image\n",
        "\n",
        "import cv2\n",
        "\n",
        "def create_video_from_frames(frames, output_path, fps):\n",
        "    \"\"\"\n",
        "    Cr√©e une vid√©o √† partir d'une liste de frames et la sauvegarde au chemin sp√©cifi√©.\n",
        "\n",
        "    Args:\n",
        "    - frames (List[np.ndarray]): Liste des images (frames) √† assembler en vid√©o.\n",
        "    - output_path (str): Chemin du fichier de sortie pour la vid√©o cr√©√©e.\n",
        "    - fps (int): Nombre de frames par seconde pour la vid√©o.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "\n",
        "    # V√©rifiez qu'il y a des frames √† traiter\n",
        "    if not frames:\n",
        "        raise ValueError(\"La liste des frames est vide.\")\n",
        "\n",
        "    # R√©cup√©rez la hauteur et la largeur de la premi√®re frame\n",
        "    height, width = frames[0].shape[:2]\n",
        "\n",
        "    # D√©finissez le codec et cr√©ez l'objet VideoWriter\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec pour les fichiers .mp4\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # √âcrivez chaque frame dans le fichier de sortie\n",
        "    for frame in frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    # Lib√©rez l'objet VideoWriter\n",
        "    out.release()\n",
        "\n"
      ],
      "metadata": {
        "id": "uF7S6p4mUiMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0751e8a0-857e-43c7-ce7f-cfb1aa475668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|‚ñà‚ñà        | 8.91M/44.1M [00:00<00:00, 38.2MB/s]\r 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 31.5M/44.1M [00:00<00:00, 109MB/s] \r100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.1M/44.1M [00:00<00:00, 104MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calcul d'angle avec une seule POV\n",
        "\n",
        "Dans cette √©tape, nous effectuons la d√©tection de pose et le calcul d'angles pour une **POV (Point Of View)** unique. Nous utilisons le mod√®le **Yolo-NAS** pour pr√©dire les poses √† partir d'une vid√©o, puis nous appliquons une fonction pour extraire les **keypoints** et calculer les angles entre certains points d'int√©r√™t sur le squelette d√©tect√©. Cette approche nous permet d'obtenir des mesures d'angles sp√©cifiques √† partir d'un seul angle de vue.\n",
        "\n",
        "Le processus est le suivant :\n",
        "1. **Pr√©diction des poses** : Utilisation de Yolo-NAS pour d√©tecter les poses dans chaque frame de la vid√©o.\n",
        "2. **Extraction des keypoints** : S√©lection des points d'int√©r√™t pour le calcul d'angles en se basant sur la structure du squelette COCO.\n",
        "3. **Calcul des angles** : Application d'une formule g√©om√©trique pour d√©terminer l'angle entre trois points choisis, offrant ainsi une mesure de l'angle d'int√©r√™t pour chaque frame.\n",
        "\n",
        "**Importance** : Cette cellule nous fournit une base solide pour comprendre comment les angles sont calcul√©s √† partir des donn√©es de pose estim√©es par le mod√®le pour une seule perspective. Cela est essentiel pour les √©tapes suivantes o√π nous envisageons d'int√©grer des donn√©es de multiples POV.\n"
      ],
      "metadata": {
        "id": "NQv_ZVPSzwUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calcul d'angle avec une seule POV\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Initialisez une liste pour stocker les donn√©es des angles pour chaque frame\n",
        "angles_data = []\n",
        "processed_frames = []\n",
        "result = yolo_nas_pose.to('cuda').predict(\"video/front1.avi\", conf=.4)\n",
        "# Remplacez ceci par votre boucle existante pour traiter chaque frame\n",
        "for frame_index, image_prediction in enumerate(result._images_prediction_gen):\n",
        "    # Ici, nous extrayons les keypoints et calculons les angles au lieu de simplement traiter l'image\n",
        "    keypoints_coordinates = extract_keypoints_for_angles(image_prediction, confidence=0.55)\n",
        "\n",
        "    # Calcul des angles pour chaque groupe de keypoints d'int√©r√™t\n",
        "    for angle_name, coords_group in keypoints_coordinates.items():\n",
        "        # Assurez-vous que nous avons exactement trois points (A, B, C)\n",
        "        if len(coords_group) == 3:\n",
        "            A, B, C = coords_group\n",
        "            angle = calculate_angle(A, B, C)\n",
        "            # Ajoutez le r√©sultat dans la liste des donn√©es\n",
        "            angles_data.append({'Frame': frame_index, 'Angle Name': angle_name, 'Angle': angle})\n",
        "\n",
        "# Cr√©ez le DataFrame √† partir de la liste des donn√©es\n",
        "df_angles = pd.DataFrame(angles_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSnpt8e8W1fv",
        "outputId": "a1dd7d75-17fb-452f-d605-01a529682c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-22 16:29:48] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
            "<ipython-input-6-61f1e69385e9>:18: RuntimeWarning: invalid value encountered in arccos\n",
            "  angle = np.arccos(cosine_angle)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calcul d'angle avec toutes les pov superpos√©es (Useless mais cod√©)\n",
        "\n",
        "Cette cellule explore l'id√©e de superposer les donn√©es de pose de **multiples POV** et de s√©lectionner la meilleure frame bas√©e sur le **score de confiance** pour chaque instant. Bien que th√©oriquement int√©ressante, cette approche s'est av√©r√©e peu pratique en raison des complications li√©es √† la fusion des perspectives et √† l'alignement des donn√©es dans un espace tridimensionnel complexe.\n",
        "\n",
        "**Raisonnement** :\n",
        "- **Superposition des donn√©es** : Tentative de combiner les informations de pose √† partir de diff√©rentes angles de vue en une repr√©sentation unifi√©e.\n",
        "- **S√©lection par score de confiance** : Choix de la frame avec le meilleur score de confiance pour chaque instant, sans tenir compte de la coh√©rence spatiale entre les diff√©rentes POV.\n",
        "\n",
        "**Conclusion** : Bien que r√©alisable, cette m√©thode introduit une complexit√© significative sans garantir une am√©lioration de la pr√©cision ou de la pertinence des mesures d'angle. Elle a donc √©t√© jug√©e moins utile pour notre objectif de mesure pr√©cise et coh√©rente des angles √† travers diff√©rentes POV.\n"
      ],
      "metadata": {
        "id": "q9X4eIZjzypm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calcul d'angle avec toute les pov superpos√©es (Useless mais cod√©)\n",
        "\n",
        "import os\n",
        "\n",
        "def process_and_select_best_frames_from_videos(video_folder, confidence_threshold=0.55):\n",
        "    video_files = [file for file in os.listdir(video_folder) if file.endswith('.mp4')]\n",
        "    best_frames_info = []  # Pour stocker le meilleur frame et son score pour chaque frame_index\n",
        "\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(video_folder, video_file)\n",
        "        result = yolo_nas_pose.to('cuda').predict(video_path, conf=confidence_threshold)\n",
        "\n",
        "        for frame_index, image_prediction in enumerate(result._images_prediction_gen):\n",
        "            # Obtenez les keypoints et calculez les angles pour la frame actuelle\n",
        "            keypoints_coordinates = extract_keypoints_for_angles(image_prediction, confidence=confidence_threshold)\n",
        "\n",
        "            # Obtenez le score de confiance global de la frame (supposant une logique pour l'obtenir)\n",
        "            frame_confidence_score = image_prediction.prediction.scores[0]  # Exemple hypoth√©tique\n",
        "\n",
        "            if len(best_frames_info) <= frame_index:\n",
        "                # Si nous n'avons pas encore trait√© ce frame_index dans d'autres vid√©os\n",
        "                best_frames_info.append({'frame': image_prediction, 'score': frame_confidence_score})\n",
        "            elif frame_confidence_score > best_frames_info[frame_index]['score']:\n",
        "                # Si le score de confiance actuel est meilleur que le meilleur pr√©c√©dent\n",
        "                best_frames_info[frame_index] = {'frame': image_prediction, 'score': frame_confidence_score}\n",
        "\n",
        "    # Apr√®s avoir examin√© toutes les vid√©os, dessinez les squelettes pour les meilleures frames s√©lectionn√©es\n",
        "    processed_frames = [process_single_image(frame_info['frame']) for frame_info in best_frames_info]\n",
        "\n",
        "    # Cr√©ez une vid√©o √† partir des meilleures frames s√©lectionn√©es\n",
        "    #create_video_from_frames(processed_frames, 'best_poses_video.mp4', fps=30)  # Assumer fps=30 pour l'exemple\n",
        "\n",
        "# Appliquez cette fonction au dossier contenant vos vid√©os\n",
        "video_folder = \"video/zipedVideo\"\n",
        "process_and_select_best_frames_from_videos(video_folder)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c4ZZ-N-NwSpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf6190a-96c0-41e0-c44f-f09b69abeed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-17 15:54:42] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calcul d'angle moyen pond√©r√© par le score de confiance avec toutes les pov\n",
        "\n",
        "Dans cette cellule, nous adoptons une approche raffin√©e pour int√©grer les donn√©es de **multiples POV** en calculant un **angle moyen pond√©r√©** bas√© sur les **scores de confiance**. Cette m√©thode tire parti des forces de chaque POV individuelle tout en att√©nuant les faiblesses potentielles li√©es √† des angles de vue sp√©cifiques.\n",
        "\n",
        "**Proc√©dure** :\n",
        "1. **Calcul individuel des angles** : Pour chaque POV, nous calculons les angles et les scores de confiance associ√©s.\n",
        "2. **Moyenne pond√©r√©e** : Les angles de chaque frame sont ensuite combin√©s en utilisant une moyenne pond√©r√©e par les scores de confiance, ce qui permet de privil√©gier les donn√©es les plus fiables.\n",
        "\n",
        "**Avantages** :\n",
        "- **Exploitation optimale des POV multiples** : Cette m√©thode permet de b√©n√©ficier de la diversit√© des points de vue sans les contraintes li√©es √† leur superposition directe.\n",
        "- **Am√©lioration de la pr√©cision** : La moyenne pond√©r√©e augmente la fiabilit√© des mesures d'angle en donnant plus de poids aux estimations les plus confiantes.\n",
        "\n",
        "**Impact** : En fin de compte, cette approche nous offre une m√©thode robuste pour analyser les mouvements et postures √† partir de vid√©os captur√©es √† partir de multiples angles, en assurant une int√©gration intelligente et efficace des donn√©es.\n"
      ],
      "metadata": {
        "id": "paRRkiS2z1Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calcul d'angle moyen pond√©r√© par confidance score avec toute les pov\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def calculate_weighted_average_angles(video_folder, confidence_threshold=0.55):\n",
        "    video_files = [file for file in os.listdir(video_folder) if file.endswith('.avi')]\n",
        "    all_frames_data = []\n",
        "\n",
        "    # √âtape 1: Calculer les angles pour chaque POV\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(video_folder, video_file)\n",
        "        result = yolo_nas_pose.to('cuda').predict(video_path, conf=confidence_threshold)\n",
        "        frames_data = []\n",
        "\n",
        "        for frame_index, image_prediction in enumerate(result._images_prediction_gen):\n",
        "            keypoints_coordinates = extract_keypoints_for_angles(image_prediction, confidence=confidence_threshold)\n",
        "            frame_data = {'Frame': frame_index}\n",
        "\n",
        "            for angle_name, coords_group in keypoints_coordinates.items():\n",
        "                if len(coords_group) == 3:\n",
        "                    A, B, C = coords_group\n",
        "                    angle = calculate_angle(A, B, C)\n",
        "                    frame_data[f'Angle {angle_name}'] = angle\n",
        "                    frame_data[f'Confidence {angle_name}'] = np.mean(image_prediction.prediction.scores)  # Exemple de calcul de confiance\n",
        "\n",
        "            frames_data.append(frame_data)\n",
        "\n",
        "        # Convertir en DataFrame et stocker dans la liste globale\n",
        "        df_video = pd.DataFrame(frames_data)\n",
        "        df_video['POV'] = video_file\n",
        "        all_frames_data.append(df_video)\n",
        "\n",
        "    # √âtape 2: Fusionner tous les DataFrames de vid√©os\n",
        "    df_all_videos = pd.concat(all_frames_data, ignore_index=True)\n",
        "\n",
        "    # Calculer la moyenne pond√©r√©e pour chaque frame et angle √† travers toutes les vid√©os\n",
        "    weighted_average_df = df_all_videos.groupby(['Frame', 'POV']).mean().reset_index()\n",
        "\n",
        "    return df_all_videos, weighted_average_df\n",
        "\n",
        "# Exemple d'utilisation\n",
        "video_folder = \"video/2\"\n",
        "df_weighted_angles,df_angles_all_videos = calculate_weighted_average_angles(video_folder)\n",
        "\n",
        "# Affichage des premi√®res lignes du DataFrame final\n",
        "print(df_weighted_angles.head())\n"
      ],
      "metadata": {
        "id": "wiLlodRFx0lD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff67e9a8-4dad-416e-a7fa-6df11ba00f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-22 17:16:31] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
            "[2024-04-22 17:18:33] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
            "<ipython-input-15-1abc26a9f1cb>:18: RuntimeWarning: invalid value encountered in arccos\n",
            "  angle = np.arccos(cosine_angle)\n",
            "[2024-04-22 17:19:25] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_angles.head()\n",
        "df_angles.to_csv(\"anglesFront1.csv\")\n",
        "df_angles_all_videos.to_csv(\"allVid2Ok.csv\")\n",
        "df_weighted_angles.to_csv('anglesW2Ok.csv')"
      ],
      "metadata": {
        "id": "q9tuTOYZXTeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture fichier xsens pour sortir un df_angles_xsens"
      ],
      "metadata": {
        "id": "DC-U6mfjqkcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gdown\n",
        "\n",
        "def process_xsens_data(xsens_path, sheet_name, column_mapping):\n",
        "\n",
        "\n",
        "    # Lire les donn√©es du fichier Excel xSens\n",
        "    df_xsens = pd.read_excel(xsens_path, sheet_name=sheet_name)\n",
        "\n",
        "    # S√©lectionner et renommer les colonnes en utilisant le dictionnaire de mappage\n",
        "    columns_of_interest = list(column_mapping.keys())\n",
        "    df_xsens_selected = df_xsens[columns_of_interest].rename(columns=column_mapping)\n",
        "\n",
        "    # Cr√©er un DataFrame avec les angles renomm√©s\n",
        "    df_angle_xsens = df_xsens_selected.rename(columns=lambda name: 'Angle ' + name)\n",
        "\n",
        "    return df_angle_xsens\n",
        "\n",
        "\n",
        "column_mapping = { # Manque des choses, c'est temporaire pour un test\n",
        "    'Frame': 'Frame',  # Assumer que le num√©ro de frame est correct\n",
        "    # Mappage des mesures de l'articulation de l'√©paule\n",
        "    'Left Shoulder Flexion/Extension': 'Bras Gauche Flexion/Extension',\n",
        "    'Right Shoulder Flexion/Extension': 'Bras Droit Flexion/Extension',\n",
        "    # Mappage des mesures de l'articulation du coude\n",
        "    'Left Elbow Flexion/Extension': 'Coude Gauche Flexion/Extension',\n",
        "    'Right Elbow Flexion/Extension': 'Coude Droit Flexion/Extension',\n",
        "    # Mappage des mesures de l'articulation de la hanche pour la jambe\n",
        "    'Left Hip Flexion/Extension': 'Jambe Gauche Flexion/Extension',\n",
        "    'Right Hip Flexion/Extension': 'Jambe Droite Flexion/Extension',\n",
        "    # Mappage des mesures de l'articulation du genou\n",
        "    'Left Knee Flexion/Extension': 'Genou Gauche Flexion/Extension',\n",
        "    'Right Knee Flexion/Extension': 'Genou Droit Flexion/Extension',\n",
        "    # Mappage des mesures de l'articulation du poignet\n",
        "    'Left Wrist Flexion/Extension': 'Poignet Gauche Flexion/Extension',\n",
        "    'Right Wrist Flexion/Extension': 'Poignet Droit Flexion/Extension',\n",
        "}\n",
        "\n",
        "\n",
        "# Utiliser la fonction\n",
        "xsens_path = 'xsensData.xlsx'\n",
        "sheet_name = 'Joint Angles ZXY'  # Ou autre feuille du fichier Excel selon vos besoins\n",
        "df_angle_xsens = process_xsens_data(xsens_path, sheet_name, column_mapping)\n"
      ],
      "metadata": {
        "id": "JjcGTjEqqp5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_angle_xsens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoOntKyesVKI",
        "outputId": "7a1f1b0e-7a91-466d-e1b6-56af1774fa33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Angle Frame  Angle Bras Gauche Flexion/Extension  \\\n",
              "0               0                            19.834392   \n",
              "1               1                            19.793270   \n",
              "2               2                            19.752140   \n",
              "3               3                            19.709416   \n",
              "4               4                            19.661376   \n",
              "...           ...                                  ...   \n",
              "4037         4037                            23.637930   \n",
              "4038         4038                            23.621237   \n",
              "4039         4039                            23.600261   \n",
              "4040         4040                            23.576672   \n",
              "4041         4041                            23.553084   \n",
              "\n",
              "      Angle Bras Droit Flexion/Extension  \\\n",
              "0                              -2.398467   \n",
              "1                              -2.464427   \n",
              "2                              -2.530390   \n",
              "3                              -2.585937   \n",
              "4                              -2.624198   \n",
              "...                                  ...   \n",
              "4037                            5.585755   \n",
              "4038                            5.573018   \n",
              "4039                            5.561873   \n",
              "4040                            5.551231   \n",
              "4041                            5.540588   \n",
              "\n",
              "      Angle Coude Gauche Flexion/Extension  \\\n",
              "0                                13.001976   \n",
              "1                                12.910597   \n",
              "2                                12.819180   \n",
              "3                                12.747469   \n",
              "4                                12.702113   \n",
              "...                                    ...   \n",
              "4037                              6.933385   \n",
              "4038                              6.937896   \n",
              "4039                              6.939000   \n",
              "4040                              6.938520   \n",
              "4041                              6.938041   \n",
              "\n",
              "      Angle Coude Droit Flexion/Extension  \\\n",
              "0                               24.503302   \n",
              "1                               24.615320   \n",
              "2                               24.722739   \n",
              "3                               24.818088   \n",
              "4                               24.894425   \n",
              "...                                   ...   \n",
              "4037                            10.380064   \n",
              "4038                            10.386678   \n",
              "4039                            10.381776   \n",
              "4040                            10.370576   \n",
              "4041                            10.359376   \n",
              "\n",
              "      Angle Jambe Gauche Flexion/Extension  \\\n",
              "0                                 8.355053   \n",
              "1                                 8.259817   \n",
              "2                                 8.164611   \n",
              "3                                 8.077358   \n",
              "4                                 8.001356   \n",
              "...                                    ...   \n",
              "4037                              4.296421   \n",
              "4038                              4.294296   \n",
              "4039                              4.292516   \n",
              "4040                              4.290861   \n",
              "4041                              4.289206   \n",
              "\n",
              "      Angle Jambe Droite Flexion/Extension  \\\n",
              "0                                 5.295085   \n",
              "1                                 5.242339   \n",
              "2                                 5.189561   \n",
              "3                                 5.137920   \n",
              "4                                 5.088158   \n",
              "...                                    ...   \n",
              "4037                              1.546671   \n",
              "4038                              1.545041   \n",
              "4039                              1.544912   \n",
              "4040                              1.545499   \n",
              "4041                              1.546086   \n",
              "\n",
              "      Angle Genou Gauche Flexion/Extension  \\\n",
              "0                                 7.227706   \n",
              "1                                 7.174970   \n",
              "2                                 7.122247   \n",
              "3                                 7.077822   \n",
              "4                                 7.045603   \n",
              "...                                    ...   \n",
              "4037                              6.051620   \n",
              "4038                              6.049739   \n",
              "4039                              6.050735   \n",
              "4040                              6.053333   \n",
              "4041                              6.055930   \n",
              "\n",
              "      Angle Genou Droit Flexion/Extension  \\\n",
              "0                                4.974105   \n",
              "1                                4.984867   \n",
              "2                                4.995629   \n",
              "3                                5.005358   \n",
              "4                                5.015176   \n",
              "...                                   ...   \n",
              "4037                             3.261265   \n",
              "4038                             3.259248   \n",
              "4039                             3.261254   \n",
              "4040                             3.265330   \n",
              "4041                             3.269406   \n",
              "\n",
              "      Angle Poignet Gauche Flexion/Extension  \\\n",
              "0                                   7.397145   \n",
              "1                                   6.457907   \n",
              "2                                   5.519434   \n",
              "3                                   4.612105   \n",
              "4                                   3.742549   \n",
              "...                                      ...   \n",
              "4037                               10.302855   \n",
              "4038                               10.317083   \n",
              "4039                               10.329662   \n",
              "4040                               10.342551   \n",
              "4041                               10.355441   \n",
              "\n",
              "      Angle Poignet Droit Flexion/Extension  \n",
              "0                                 -0.147721  \n",
              "1                                 -0.199729  \n",
              "2                                 -0.255811  \n",
              "3                                 -0.545159  \n",
              "4                                 -1.195650  \n",
              "...                                     ...  \n",
              "4037                              -3.252249  \n",
              "4038                              -3.252079  \n",
              "4039                              -3.247059  \n",
              "4040                              -3.239248  \n",
              "4041                              -3.231440  \n",
              "\n",
              "[4042 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68e02b3e-a932-4a78-9c3f-3361c40af7d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Angle Frame</th>\n",
              "      <th>Angle Bras Gauche Flexion/Extension</th>\n",
              "      <th>Angle Bras Droit Flexion/Extension</th>\n",
              "      <th>Angle Coude Gauche Flexion/Extension</th>\n",
              "      <th>Angle Coude Droit Flexion/Extension</th>\n",
              "      <th>Angle Jambe Gauche Flexion/Extension</th>\n",
              "      <th>Angle Jambe Droite Flexion/Extension</th>\n",
              "      <th>Angle Genou Gauche Flexion/Extension</th>\n",
              "      <th>Angle Genou Droit Flexion/Extension</th>\n",
              "      <th>Angle Poignet Gauche Flexion/Extension</th>\n",
              "      <th>Angle Poignet Droit Flexion/Extension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>19.834392</td>\n",
              "      <td>-2.398467</td>\n",
              "      <td>13.001976</td>\n",
              "      <td>24.503302</td>\n",
              "      <td>8.355053</td>\n",
              "      <td>5.295085</td>\n",
              "      <td>7.227706</td>\n",
              "      <td>4.974105</td>\n",
              "      <td>7.397145</td>\n",
              "      <td>-0.147721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>19.793270</td>\n",
              "      <td>-2.464427</td>\n",
              "      <td>12.910597</td>\n",
              "      <td>24.615320</td>\n",
              "      <td>8.259817</td>\n",
              "      <td>5.242339</td>\n",
              "      <td>7.174970</td>\n",
              "      <td>4.984867</td>\n",
              "      <td>6.457907</td>\n",
              "      <td>-0.199729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>19.752140</td>\n",
              "      <td>-2.530390</td>\n",
              "      <td>12.819180</td>\n",
              "      <td>24.722739</td>\n",
              "      <td>8.164611</td>\n",
              "      <td>5.189561</td>\n",
              "      <td>7.122247</td>\n",
              "      <td>4.995629</td>\n",
              "      <td>5.519434</td>\n",
              "      <td>-0.255811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>19.709416</td>\n",
              "      <td>-2.585937</td>\n",
              "      <td>12.747469</td>\n",
              "      <td>24.818088</td>\n",
              "      <td>8.077358</td>\n",
              "      <td>5.137920</td>\n",
              "      <td>7.077822</td>\n",
              "      <td>5.005358</td>\n",
              "      <td>4.612105</td>\n",
              "      <td>-0.545159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>19.661376</td>\n",
              "      <td>-2.624198</td>\n",
              "      <td>12.702113</td>\n",
              "      <td>24.894425</td>\n",
              "      <td>8.001356</td>\n",
              "      <td>5.088158</td>\n",
              "      <td>7.045603</td>\n",
              "      <td>5.015176</td>\n",
              "      <td>3.742549</td>\n",
              "      <td>-1.195650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4037</th>\n",
              "      <td>4037</td>\n",
              "      <td>23.637930</td>\n",
              "      <td>5.585755</td>\n",
              "      <td>6.933385</td>\n",
              "      <td>10.380064</td>\n",
              "      <td>4.296421</td>\n",
              "      <td>1.546671</td>\n",
              "      <td>6.051620</td>\n",
              "      <td>3.261265</td>\n",
              "      <td>10.302855</td>\n",
              "      <td>-3.252249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4038</th>\n",
              "      <td>4038</td>\n",
              "      <td>23.621237</td>\n",
              "      <td>5.573018</td>\n",
              "      <td>6.937896</td>\n",
              "      <td>10.386678</td>\n",
              "      <td>4.294296</td>\n",
              "      <td>1.545041</td>\n",
              "      <td>6.049739</td>\n",
              "      <td>3.259248</td>\n",
              "      <td>10.317083</td>\n",
              "      <td>-3.252079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4039</th>\n",
              "      <td>4039</td>\n",
              "      <td>23.600261</td>\n",
              "      <td>5.561873</td>\n",
              "      <td>6.939000</td>\n",
              "      <td>10.381776</td>\n",
              "      <td>4.292516</td>\n",
              "      <td>1.544912</td>\n",
              "      <td>6.050735</td>\n",
              "      <td>3.261254</td>\n",
              "      <td>10.329662</td>\n",
              "      <td>-3.247059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4040</th>\n",
              "      <td>4040</td>\n",
              "      <td>23.576672</td>\n",
              "      <td>5.551231</td>\n",
              "      <td>6.938520</td>\n",
              "      <td>10.370576</td>\n",
              "      <td>4.290861</td>\n",
              "      <td>1.545499</td>\n",
              "      <td>6.053333</td>\n",
              "      <td>3.265330</td>\n",
              "      <td>10.342551</td>\n",
              "      <td>-3.239248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4041</th>\n",
              "      <td>4041</td>\n",
              "      <td>23.553084</td>\n",
              "      <td>5.540588</td>\n",
              "      <td>6.938041</td>\n",
              "      <td>10.359376</td>\n",
              "      <td>4.289206</td>\n",
              "      <td>1.546086</td>\n",
              "      <td>6.055930</td>\n",
              "      <td>3.269406</td>\n",
              "      <td>10.355441</td>\n",
              "      <td>-3.231440</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4042 rows √ó 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68e02b3e-a932-4a78-9c3f-3361c40af7d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68e02b3e-a932-4a78-9c3f-3361c40af7d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68e02b3e-a932-4a78-9c3f-3361c40af7d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ea76ba6-7f2a-46fc-9466-0dde66c2ca25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ea76ba6-7f2a-46fc-9466-0dde66c2ca25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ea76ba6-7f2a-46fc-9466-0dde66c2ca25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_angle_xsens",
              "summary": "{\n  \"name\": \"df_angle_xsens\",\n  \"rows\": 4042,\n  \"fields\": [\n    {\n      \"column\": \"Angle Frame\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1166,\n        \"min\": 0,\n        \"max\": 4041,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          4003,\n          149,\n          2025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Bras Gauche Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.612099939620144,\n        \"min\": -41.7933302671542,\n        \"max\": 129.485818698227,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          23.8520720304949,\n          20.1730644654862,\n          20.3103445401949\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Bras Droit Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.921074701974796,\n        \"min\": -69.5595846249841,\n        \"max\": 122.269799010882,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          5.47646753079063,\n          -2.1910382655934,\n          8.99655196433919\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Coude Gauche Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.624708154619,\n        \"min\": -8.8597755296013,\n        \"max\": 143.737203083919,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          6.90563876961562,\n          69.1993553814564,\n          -0.100389731586212\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Coude Droit Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34.93395292790922,\n        \"min\": 1.26663033467473,\n        \"max\": 150.298083945418,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          10.405981168136,\n          86.3857274000514,\n          11.3476885356835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Jambe Gauche Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.395683234570122,\n        \"min\": -2.20057192066431,\n        \"max\": 95.0465063484827,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          4.48343783302359,\n          6.83755579317801,\n          8.32605569754133\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Jambe Droite Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.736888844794775,\n        \"min\": -4.75175276154791,\n        \"max\": 85.937309149168,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          1.77634093756287,\n          3.95250715509854,\n          5.27893356391276\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Genou Gauche Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.331522395111502,\n        \"min\": 1.78932657708158,\n        \"max\": 119.951794784146,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          6.04408182913287,\n          6.89901622640001,\n          6.410498475274\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Genou Droit Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.95510427566676,\n        \"min\": 0.813112332199874,\n        \"max\": 113.651940396981,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          3.2907576886293,\n          4.74619987506366,\n          3.35103240358109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Poignet Gauche Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.132913337570955,\n        \"min\": -52.6773647297228,\n        \"max\": 76.9390280192354,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          10.0568967826963,\n          -19.2240027600566,\n          1.25361774784398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Poignet Droit Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.777549091954995,\n        \"min\": -46.1951638017126,\n        \"max\": 59.6488550834668,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          -3.30903962459967,\n          -15.7074288169386,\n          -5.21814132377756\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction pour dessiner le Squelette"
      ],
      "metadata": {
        "id": "-3PY7HdIhlnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Sur toute les pov\n",
        "import os\n",
        "\n",
        "def process_all_videos(video_folder):\n",
        "    # Liste tous les fichiers dans le dossier\n",
        "    video_files = [file for file in os.listdir(video_folder) if file.endswith('.mp4')]\n",
        "\n",
        "    for video_file in video_files:\n",
        "        # Pr√©parez une liste pour collecter les frames trait√©es\n",
        "        processed_frames = []\n",
        "\n",
        "        # Chemin complet vers la vid√©o\n",
        "        video_path = os.path.join(video_folder, video_file)\n",
        "\n",
        "        # Pr√©diction des poses pour la vid√©o actuelle\n",
        "        result = yolo_nas_pose.to('cuda').predict(video_path, conf=.4)\n",
        "\n",
        "        # It√©rer sur chaque pr√©diction d'image dans le g√©n√©rateur\n",
        "        for image_prediction in result._images_prediction_gen:\n",
        "            # Appliquez le traitement n√©cessaire pour chaque image\n",
        "            # En utilisant une fonction `process_single_image` pour dessiner les squelettes\n",
        "            processed_image = process_single_image(image_prediction)\n",
        "            processed_frames.append(processed_image)\n",
        "\n",
        "        # Apr√®s avoir collect√© toutes les frames trait√©es, cr√©ez une vid√©o\n",
        "        # Le nom de la vid√©o de sortie est bas√© sur le nom du fichier d'entr√©e\n",
        "        output_video_path = os.path.join(video_folder, f\"skeleton_{video_file}\")\n",
        "        create_video_from_frames(processed_frames, output_video_path, fps=result.fps)\n",
        "\n",
        "# Utilisez cette fonction en sp√©cifiant le chemin du dossier contenant vos vid√©os\n",
        "video_folder = \"video/zipedVideo\"\n",
        "process_all_videos(video_folder)\n"
      ],
      "metadata": {
        "id": "dcdP05X4tJBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2a0581b-ff55-40dc-e153-da066dcfb57d",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-18 18:56:30] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# URL du fichier ZIP sur Google Drive\n",
        "url = 'https://drive.google.com/uc?id=1ngVS0Qfn5NqR1yvc64lP8BE-96Dg3Lvi'\n",
        "\n",
        "output_zip_path = '/content/video_archive.zip'\n",
        "\n",
        "# Dossier cible pour extraire le contenu du fichier ZIP\n",
        "extract_to_folder = '/content/video2'\n",
        "\n",
        "# Cr√©ez le dossier s'il n'existe pas\n",
        "if not os.path.exists(extract_to_folder):\n",
        "    os.makedirs(extract_to_folder)\n",
        "\n",
        "# T√©l√©chargez le fichier ZIP\n",
        "gdown.download(url, output_zip_path, quiet=False)\n",
        "\n",
        "# D√©compressez le fichier ZIP\n",
        "with zipfile.ZipFile(output_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_folder)\n",
        "\n",
        "# Supprimez le fichier ZIP si vous n'en avez plus besoin\n",
        "os.remove(output_zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9vZ8qNZXlA-",
        "outputId": "8986f428-02c9-45bb-883c-216145193363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ngVS0Qfn5NqR1yvc64lP8BE-96Dg3Lvi\n",
            "From (redirected): https://drive.google.com/uc?id=1ngVS0Qfn5NqR1yvc64lP8BE-96Dg3Lvi&confirm=t&uuid=c543a8cb-8243-4951-a79f-e6445021e75c\n",
            "To: /content/video_archive.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.9M/42.9M [00:00<00:00, 51.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sur une seule pov\n",
        "\n",
        "\n",
        "# Pr√©parez une liste pour collecter les frames trait√©es\n",
        "\n",
        "processed_frames = []\n",
        "result = yolo_nas_pose.to('cuda').predict(\"video2/side1.mp4\", conf=.4)\n",
        "# It√©rez sur chaque pr√©diction d'image dans le g√©n√©rateur\n",
        "for image_prediction in result._images_prediction_gen:\n",
        "    # Appliquez le traitement n√©cessaire pour chaque image\n",
        "    # Par exemple, en utilisant une fonction fictive `process_single_image` que vous devez d√©finir ou adapter\n",
        "    processed_image = process_single_image(image_prediction)\n",
        "    processed_frames.append(processed_image)\n",
        "\n",
        "\n",
        "# Apr√®s avoir collect√© toutes les frames trait√©es, cr√©ez une vid√©o\n",
        "# Assurez-vous d'avoir une fonction `create_video_from_frames` qui prend la liste des frames et le chemin de sortie\n",
        "create_video_from_frames(processed_frames, 'side1Skeleton.mp4', fps=result.fps)"
      ],
      "metadata": {
        "id": "uvIKqebIuhK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4a3054-74c5-4b78-f429-823cb6752718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-22 19:58:17] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PHwVb_MUucDr"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "DC-U6mfjqkcR",
        "-3PY7HdIhlnV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}