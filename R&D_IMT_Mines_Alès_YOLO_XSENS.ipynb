{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamiCakiral/escrim-stock-management/blob/main/R%26D_IMT_Mines_Al%C3%A8s_YOLO_XSENS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP0yAiIAJm_c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install super-gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX08s9XVTM_2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "from imutils import paths\n",
        "from IPython.display import YouTubeVideo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "may0acXMJnUS"
      },
      "source": [
        "# Instantiate the model!\n",
        "\n",
        "Start by instantiating a pretrained model. YOLO-NAS-Pose comes in three flavors: `yolo_nas_pose_s`, `yolo_nas_pose_m`, and `yolo_nas_pose_l`.\n",
        "\n",
        "You'll use `yolo_nas_pose_l` throughout this notebook. Because you should always go big, or go home.\n",
        "\n",
        "It's a good life philosophy.\n",
        "\n",
        "**Note:** I am using a High-RAM instance of a T4 when running this notebook. If you don't have access to the High-RAM instance, I suggest trying the medium or small versions of the model. If you think you have enough RAM, but find this taking too much memory for your liking, set `fuse_model=False` in the `predict` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbDPi-8VNbFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7104e60-da11-4b02-ad17-e47997af7b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-22 19:45:55] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is logged into /root/sg_logs/console.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-22 19:46:07] INFO - utils.py - NumExpr defaulting to 2 threads.\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: boto3 required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: deprecated required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: coverage required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: sphinx-rtd-theme required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: torchmetrics required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: hydra-core required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: omegaconf required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnxruntime required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnx required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: pillow==9.4.0 does not satisfy requirement pillow>=10.2.0\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: einops required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: treelib required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: stringcase required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: rapidfuzz required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: json-tricks required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnxsim required but not found\u001b[0m\n",
            "[2024-04-22 19:46:11] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: data-gradients required but not found\u001b[0m\n",
            "[2024-04-22 19:46:12] WARNING - checkpoint_utils.py - :warning: The pre-trained models provided by SuperGradients may have their own licenses or terms and conditions derived from the dataset used for pre-training.\n",
            " It is your responsibility to determine whether you have permission to use the models for your use case.\n",
            " The model you have requested was pre-trained on the coco_pose dataset, published under the following terms: https://cocodataset.org/#termsofuse\n",
            "[2024-04-22 19:46:12] INFO - checkpoint_utils.py - License Notification: YOLO-NAS-POSE pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
            "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS-POSE.md\n",
            "By downloading the pre-trained weight files you agree to comply with these terms.\n",
            "Downloading: \"https://sghub.deci.ai/models/yolo_nas_pose_l_coco_pose.pth\" to /root/.cache/torch/hub/checkpoints/yolo_nas_pose_l_coco_pose.pth\n",
            "100%|██████████| 304M/304M [00:01<00:00, 227MB/s]\n",
            "[2024-04-22 19:46:14] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_pose_l\n"
          ]
        }
      ],
      "source": [
        "from super_gradients.training import models\n",
        "from super_gradients.common.object_names import Models\n",
        "\n",
        "yolo_nas_pose = models.get(\"yolo_nas_pose_l\", pretrained_weights=\"coco_pose\").cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yOwWRkEOXxG"
      },
      "source": [
        "## 🖼️  Predicting is a one-liner: `yolo_nas_pose.to(device).predict(input_file)`\n",
        "\n",
        "Once the model has been instantiated all you have to do is call the `predict` method. The `predict()` method is built to handle multiple data formats and types.\n",
        "\n",
        "Here is the full list of what `predict()` method can handle:\n",
        "\n",
        "| Argument Semantics                 | Argument Type      | Supported layout                  | Example                                                                                        | Notes                                                                                            |\n",
        "|------------------------------------|--------------------|-----------------------------------|------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
        "| Path to local image                | `str`              | -                                 | `predict(\"path/to/image.jpg\")`                                                                 | All common image extensions are supported.                                                       |\n",
        "| Path to images directory           | `str`              | -                                 | `predict(\"path/to/images/directory\")`                                                          |                                                                                                  |\n",
        "| Path to local video                | `str`              | -                                 | `predict(\"path/to/video.mp4\")`                                                                 | All common video extensions are supported.                                                       |\n",
        "| URL to remote image                | `str`              | -                                 | `predict(\"https://example.com/image.jpg\")`                                                     |                                                                                                  |\n",
        "| 3-dimensional Numpy image          | `np.ndarray`       | `[H, W, C]`                       | `predict(np.zeros((480, 640, 3), dtype=np.uint8))`                                             | Channels last, RGB channel order for 3-channel images                                            |\n",
        "| 4-dimensional Numpy image          | `np.ndarray`       | `[N, H, W, C]` or `[N, C, H, W]`  | `predict(np.zeros((480, 640, 3), dtype=np.uint8))`                                             | Tensor layout (NHWC or NCHW) is inferred w.r.t to number of input channels of underlying model   |\n",
        "| List of 3-dimensional numpy arrays | `List[np.ndarray]` | `[H1, W1, C]`, `[H2, W2, C]`, ... | `predict([np.zeros((480, 640, 3), dtype=np.uint8), np.zeros((384, 512, 3), dtype=np.uint8) ])` | Images may vary in size, but should have same number of channels                                 |\n",
        "| 3-dimensional Torch Tensor         | `torch.Tensor`     | `[H, W, C]` or `[C, H, W]`        | `predict(torch.zeros((480, 640, 3), dtype=torch.uint8))`                                       | Tensor layout (HWC or CHW) is inferred w.r.t to number of input channels of underlying model     |\n",
        "| 4-dimensional Torch Tensor         | `torch.Tensor`     | `[N, H, W, C]` or `[N, C, H, W]`  | `predict(torch.zeros((4, 480, 640, 3), dtype=torch.uint8))`                                    | Tensor layout (NHWC or NCHW) is inferred w.r.t to number of input channels of underlying model   |\n",
        "\n",
        "**Important note** - When using batched input (4-dimensional `np.ndarray` or `torch.Tensor`) formats, **normalization and size preprocessing will be applied to these inputs**.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### For more details about predicting using YOLO-NAS-Pose, check out the [docs](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/ModelPredictions.md)\n",
        "\n",
        "### Let's wrap the predict method in a function just for this notebook. But really it's just one line to predict! And this is it: `yolo_nas_pose.to(device).predict(input_file)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hNHxSUs5E9M"
      },
      "outputs": [],
      "source": [
        "# @title Run this cell for prediction function\n",
        "def make_prediction(input_file, action, confidence=0.55):\n",
        "    \"\"\"\n",
        "    Make a prediction using the fixed model and device, and either show or save the result.\n",
        "\n",
        "    Args:\n",
        "    - input_file (str): Path to the input file.\n",
        "    - action (str): Either 'show' or 'save'.\n",
        "    - confidence (float, optional): Confidence threshold. Defaults to 0.75.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "\n",
        "    Raises:\n",
        "    - ValueError: If the action is not 'show' or 'save'.\n",
        "    \"\"\"\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    if action == \"show\":\n",
        "        yolo_nas_pose.to(device).predict(input_file, conf=confidence).show()\n",
        "    elif action == \"save\":\n",
        "        output_file = pathlib.Path(input_file).stem + \"-detections\" + pathlib.Path(input_file).suffix\n",
        "        yolo_nas_pose.to(device).predict(input_file, conf=confidence).save(output_file)\n",
        "        print(f\"Prediction saved to {output_file}\")\n",
        "    else:\n",
        "        raise ValueError(\"Action must be either 'show' or 'save'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE7gUJA4tS0k"
      },
      "source": [
        "# 📽️ Inference on video"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Videos\n",
        "\n",
        "Code pour charger toute les vidéos de test"
      ],
      "metadata": {
        "id": "tSZ2haevPDu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# URL du fichier ZIP sur Google Drive\n",
        "url = 'https://drive.google.com/uc?id=1-k23dMqskWcYF4KAoMA0yql5kO-1LQRk'\n",
        "https://drive.google.com/file/d/18stBvPNgiNPPYHZGjuaQq2ym7UZ798Fo/view?usp=share_link\n",
        "output_zip_path = '/content/video_archive.zip'\n",
        "\n",
        "# Dossier cible pour extraire le contenu du fichier ZIP\n",
        "extract_to_folder = '/content/video'\n",
        "\n",
        "# Créez le dossier s'il n'existe pas\n",
        "if not os.path.exists(extract_to_folder):\n",
        "    os.makedirs(extract_to_folder)\n",
        "\n",
        "# Téléchargez le fichier ZIP\n",
        "gdown.download(url, output_zip_path, quiet=False)\n",
        "\n",
        "# Décompressez le fichier ZIP\n",
        "with zipfile.ZipFile(output_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_folder)\n",
        "\n",
        "# Supprimez le fichier ZIP si vous n'en avez plus besoin\n",
        "os.remove(output_zip_path)\n",
        "\n",
        "print(f'Les vidéos ont été extraites dans {extract_to_folder}')\n",
        "\n",
        "url ='https://drive.google.com/uc?id=1hUFaYw6RR2couxLqBJ1tQm0mp_1_Qj-k'\n",
        "output = 'xsensData.xlsx'  # Remplacez par le nom que vous souhaitez donner au fichier téléchargé\n",
        "\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "-uOay6sOPDNr",
        "outputId": "f197ceff-7762-4080-bcf4-c36b62ebfcf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-k23dMqskWcYF4KAoMA0yql5kO-1LQRk\n",
            "From (redirected): https://drive.google.com/uc?id=1-k23dMqskWcYF4KAoMA0yql5kO-1LQRk&confirm=t&uuid=476af17c-6c74-437f-a66e-c1dffe0b5c5e\n",
            "To: /content/video_archive.zip\n",
            "100%|██████████| 1.91G/1.91G [00:21<00:00, 88.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les vidéos ont été extraites dans /content/video\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hUFaYw6RR2couxLqBJ1tQm0mp_1_Qj-k\n",
            "To: /content/xsensData.xlsx\n",
            "\r  0%|          | 0.00/44.1M [00:00<?, ?B/s]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xsensData.xlsx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# URL du fichier ZIP sur Google Drive\n",
        "url = 'https://drive.google.com/uc?id=18stBvPNgiNPPYHZGjuaQq2ym7UZ798Fo'\n",
        "\n",
        "output_zip_path = '/content/csv.zip'\n",
        "\n",
        "# Dossier cible pour extraire le contenu du fichier ZIP\n",
        "extract_to_folder = '/content/csv'\n",
        "\n",
        "# Créez le dossier s'il n'existe pas\n",
        "if not os.path.exists(extract_to_folder):\n",
        "    os.makedirs(extract_to_folder)\n",
        "\n",
        "# Téléchargez le fichier ZIP\n",
        "gdown.download(url, output_zip_path, quiet=False)\n",
        "\n",
        "# Décompressez le fichier ZIP\n",
        "with zipfile.ZipFile(output_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_folder)\n",
        "\n",
        "# Supprimez le fichier ZIP si vous n'en avez plus besoin\n",
        "os.remove(output_zip_path)\n",
        "\n",
        "print(f'Les fichiers CSV ont été extraits dans {extract_to_folder}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "f197ceff-7762-4080-bcf4-c36b62ebfcf1",
        "id": "pPXrlCkCMNZW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-k23dMqskWcYF4KAoMA0yql5kO-1LQRk\n",
            "From (redirected): https://drive.google.com/uc?id=1-k23dMqskWcYF4KAoMA0yql5kO-1LQRk&confirm=t&uuid=476af17c-6c74-437f-a66e-c1dffe0b5c5e\n",
            "To: /content/video_archive.zip\n",
            "100%|██████████| 1.91G/1.91G [00:21<00:00, 88.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les vidéos ont été extraites dans /content/video\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hUFaYw6RR2couxLqBJ1tQm0mp_1_Qj-k\n",
            "To: /content/xsensData.xlsx\n",
            "\r  0%|          | 0.00/44.1M [00:00<?, ?B/s]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xsensData.xlsx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction pour le calcul des angles et du score + Squelette"
      ],
      "metadata": {
        "id": "--vN3i0UUivy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour analyser les poses humaines à partir de vidéos ou d'images en utilisant le modèle **YoloNAS**, qui est entraîné sur le dataset **COCO**, nous avons développé un protocole spécifique pour extraire, calculer et analyser les angles formés par différents points du squelette humain. Voici une explication claire du processus en plusieurs étapes :\n",
        "\n",
        "### 1. **Extraction des Keypoints**\n",
        "\n",
        "Chaque prédiction de pose fournie par YoloNAS renferme un ensemble de points clés (**keypoints**) correspondant aux articulations du corps humain, disposés selon la norme COCO. Ces keypoints incluent des parties cruciales du corps telles que les épaules, les coudes, les poignets, les hanches, les genoux et les chevilles, ainsi que le nez, les yeux et les oreilles, offrant une représentation complète du squelette humain.\n",
        "\n",
        "### 2. **Définition des Angles d'Intérêt**\n",
        "\n",
        "Pour procéder à l'analyse, nous définissons d'abord les angles d'intérêt en fonction des connexions naturelles entre les articulations. Par exemple, l'angle du coude gauche est formé par les keypoints de l'épaule gauche, du coude gauche et du poignet gauche. Cette approche est appliquée à diverses parties du corps pour extraire des informations pertinentes sur la posture.\n",
        "\n",
        "### 3. **Calcul des Angles**\n",
        "\n",
        "La fonction `calculate_angle` calcule l'angle en degrés au point B (l'articulation centrale, par exemple, le coude ou le genou) en utilisant la loi des cosinus. Cette loi mathématique permet de déterminer l'angle formé entre deux segments de ligne (AB et BC) à partir des longueurs des côtés d'un triangle et du produit scalaire des vecteurs. Ce calcul est essentiel pour quantifier la position et le mouvement des différentes parties du corps.\n",
        "\n",
        "### 4. **Extraction et Préparation des Données**\n",
        "\n",
        "Nous avons développé la fonction `extract_keypoints_for_angles` pour extraire spécifiquement les coordonnées nécessaires au calcul des angles d'intérêt à partir des prédictions de pose. Cette fonction filtre les poses en fonction d'un seuil de confiance pour assurer la fiabilité des données extraites.\n",
        "\n",
        "### 5. **Stockage et Analyse des Résultats**\n",
        "\n",
        "Les angles calculés pour chaque frame d'une vidéo ou pour chaque image sont ensuite stockés dans un DataFrame pandas par la fonction `calculate_and_store_angles`. Ce DataFrame organise les données de manière à faciliter l'analyse, avec une ligne par frame et une colonne pour chaque angle calculé, permettant ainsi une visualisation claire de l'évolution des postures dans le temps.\n",
        "\n",
        "### Résumé\n",
        "\n",
        "En somme, ce protocole offre une méthode systématique et précise pour l'analyse des postures humaines en se basant sur les prédictions de pose du modèle **YoloNAS** entraîné sur le dataset **COCO**. Grâce à l'extraction minutieuse des keypoints, au calcul rigoureux des angles entre les articulations et à l'organisation structurée des données résultantes, nous pouvons obtenir des insights détaillés sur la posture et le mouvement des sujets capturés dans les vidéos ou les images analysées.\n"
      ],
      "metadata": {
        "id": "izwnhRg6eNHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Fonctions pour le calcul d'angle\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calculate_angle(A, B, C):\n",
        "    \"\"\"\n",
        "    Calcule l'angle en degrés au point B entre les segments formés par les points A, B, et C.\n",
        "\n",
        "    Args:\n",
        "    - A, B, C: Coordonnées des points (x, y) sous forme de tuples ou listes.\n",
        "\n",
        "    Returns:\n",
        "    - angle_degrees: L'angle en degrés au point B.\n",
        "    \"\"\"\n",
        "    BA = np.array(A) - np.array(B)\n",
        "    BC = np.array(C) - np.array(B)\n",
        "    cosine_angle = np.dot(BA, BC) / (np.linalg.norm(BA) * np.linalg.norm(BC))\n",
        "    angle = np.arccos(cosine_angle)\n",
        "    angle_degrees = np.degrees(angle)\n",
        "    return angle_degrees\n",
        "\n",
        "def extract_keypoints_for_angles(image_prediction, confidence=0.55):\n",
        "    \"\"\"\n",
        "    Extrait les coordonnées des keypoints pour les poses détectées dans une image,\n",
        "    filtrées par un seuil de confiance, pour une structure de pose basée sur COCO.\n",
        "\n",
        "    Args:\n",
        "    - image_prediction (ImagePoseEstimationPrediction): Le résultat de la prédiction pour une image unique.\n",
        "    - confidence (float, optional): Seuil de confiance pour filtrer les poses. Par défaut à 0.55.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Un dictionnaire contenant les coordonnées des keypoints pour les angles d'intérêt.\n",
        "    \"\"\"\n",
        "    # Définition basée sur COCO keypoints\n",
        "    skeleton_structure = {\n",
        "        'Bras Gauche': (11, 5, 9),  # Hanche gauche, Épaule gauche, Poignet gauche\n",
        "        'Bras Droit': (12, 6, 10),  # Hanche droite, Épaule droite, Poignet droit\n",
        "        'Coude Gauche': (5, 7, 9),  # Épaule gauche, Coude gauche, Poignet gauche\n",
        "        'Coude Droit': (6, 8, 10),  # Épaule droite, Coude droit, Poignet droit\n",
        "        'Jambe Gauche': (0, 11, 15),  # Nez (comme substitut pour le buste), Hanche gauche, Cheville gauche\n",
        "        'Jambe Droite': (0, 12, 16),  # Nez (comme substitut pour le buste), Hanche droite, Cheville droite\n",
        "        'Genou Gauche': (11, 13, 15),  # Hanche gauche, Genou gauche, Cheville gauche\n",
        "        'Genou Droit': (12, 14, 16),  # Hanche droite, Genou droit, Cheville droite\n",
        "        'Poignet Gauche': (5, 7, 9),  # Épaule gauche, Coude gauche, Poignet gauche\n",
        "        'Poignet Droit': (6, 8, 10)   # Épaule droite, Coude droit, Poignet droit\n",
        "    }\n",
        "\n",
        "\n",
        "    keypoints_coordinates = {}\n",
        "    if image_prediction.prediction.scores.size > 0 and image_prediction.prediction.poses.size > 0:\n",
        "      # Assurez-vous d'extraire les coordonnées pour la pose la plus confiante\n",
        "      if image_prediction.prediction.scores[0] > confidence:\n",
        "          pose = image_prediction.prediction.poses[0]  # Prendre la première pose pour l'exemple\n",
        "\n",
        "          for angle_name, (p1, p2, p3) in skeleton_structure.items():\n",
        "              # Extraire les coordonnées (x, y) pour chaque groupe de points\n",
        "              A = (pose[p1][0], pose[p1][1])\n",
        "              B = (pose[p2][0], pose[p2][1])\n",
        "              C = (pose[p3][0], pose[p3][1])\n",
        "\n",
        "              keypoints_coordinates[angle_name] = [A, B, C]\n",
        "\n",
        "    return keypoints_coordinates\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "def calculate_and_store_angles(image_predictions, confidence=0.55):\n",
        "    \"\"\"\n",
        "    Pour chaque prédiction d'image, calcule les angles spécifiés et stocke les résultats dans un DataFrame\n",
        "    avec une ligne par frame et une colonne pour chaque angle.\n",
        "\n",
        "    Args:\n",
        "    - image_predictions (List[ImagePoseEstimationPrediction]): Liste des prédictions pour chaque image/frame.\n",
        "    - confidence (float): Seuil de confiance pour prendre en compte une prédiction.\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame: Un DataFrame contenant les angles calculés pour chaque frame/image, structuré par frame.\n",
        "    \"\"\"\n",
        "    # Initialisation d'une liste pour stocker les données de chaque frame/image\n",
        "    angles_data = []\n",
        "\n",
        "    for i, image_prediction in enumerate(image_predictions):\n",
        "        # Dictionnaire pour stocker les angles de la frame courante\n",
        "        frame_angles = {'Frame': i}\n",
        "\n",
        "        # Extraction des coordonnées des keypoints pour les angles d'intérêt\n",
        "        keypoints_coordinates = extract_keypoints_for_angles(image_prediction, confidence)\n",
        "\n",
        "        # Calcul des angles pour chaque groupe de keypoints d'intérêt\n",
        "        for angle_name, coords_group in keypoints_coordinates.items():\n",
        "            # Assurez-vous que nous avons exactement trois points (A, B, C)\n",
        "            if len(coords_group) == 3:\n",
        "                A, B, C = coords_group\n",
        "                angle = calculate_angle(A, B, C)\n",
        "                # Ajoutez l'angle calculé au dictionnaire de la frame courante\n",
        "                frame_angles[f'Angle {angle_name}'] = angle\n",
        "\n",
        "        # Ajoutez les angles de la frame courante à la liste des données\n",
        "        angles_data.append(frame_angles)\n",
        "\n",
        "    # Créez le DataFrame à partir de la liste des données\n",
        "    df = pd.DataFrame(angles_data)\n",
        "\n",
        "    # Réordonnez les colonnes pour mettre 'Frame' en première position si nécessaire\n",
        "    cols = ['Frame'] + [col for col in df.columns if col != 'Frame']\n",
        "    df = df[cols]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pathlib\n",
        "\n",
        "def process_single_image(image_prediction, confidence=0.55):\n",
        "    \"\"\"\n",
        "    Process a single image prediction by drawing the detected poses on the image.\n",
        "\n",
        "    Args:\n",
        "    - image_prediction (ImagePoseEstimationPrediction): The prediction result for a single image.\n",
        "    - confidence (float, optional): Confidence threshold. Defaults to 0.55.\n",
        "\n",
        "    Returns:\n",
        "    - np.ndarray: The processed image with drawn poses.\n",
        "    \"\"\"\n",
        "    # Assurez-vous que le seuil de confiance est respecté pour chaque prédiction\n",
        "    filtered_poses = [pose for pose, score in zip(image_prediction.prediction.poses, image_prediction.prediction.scores) if score > confidence]\n",
        "\n",
        "    # Dessinez les poses filtrées sur l'image. Vous pouvez adapter les arguments en fonction de vos besoins spécifiques\n",
        "    processed_image = image_prediction.draw(\n",
        "        joint_thickness=2,  # Épaisseur des joints\n",
        "        keypoint_radius=3,  # Rayon des keypoints\n",
        "        box_thickness=2,    # Épaisseur des boîtes\n",
        "        show_confidence=True  # Afficher les scores de confiance\n",
        "    )\n",
        "\n",
        "    return processed_image\n",
        "\n",
        "import cv2\n",
        "\n",
        "def create_video_from_frames(frames, output_path, fps):\n",
        "    \"\"\"\n",
        "    Crée une vidéo à partir d'une liste de frames et la sauvegarde au chemin spécifié.\n",
        "\n",
        "    Args:\n",
        "    - frames (List[np.ndarray]): Liste des images (frames) à assembler en vidéo.\n",
        "    - output_path (str): Chemin du fichier de sortie pour la vidéo créée.\n",
        "    - fps (int): Nombre de frames par seconde pour la vidéo.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "\n",
        "    # Vérifiez qu'il y a des frames à traiter\n",
        "    if not frames:\n",
        "        raise ValueError(\"La liste des frames est vide.\")\n",
        "\n",
        "    # Récupérez la hauteur et la largeur de la première frame\n",
        "    height, width = frames[0].shape[:2]\n",
        "\n",
        "    # Définissez le codec et créez l'objet VideoWriter\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec pour les fichiers .mp4\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Écrivez chaque frame dans le fichier de sortie\n",
        "    for frame in frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    # Libérez l'objet VideoWriter\n",
        "    out.release()\n",
        "\n"
      ],
      "metadata": {
        "id": "uF7S6p4mUiMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0751e8a0-857e-43c7-ce7f-cfb1aa475668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 8.91M/44.1M [00:00<00:00, 38.2MB/s]\r 71%|███████▏  | 31.5M/44.1M [00:00<00:00, 109MB/s] \r100%|██████████| 44.1M/44.1M [00:00<00:00, 104MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calcul d'angle avec une seule POV\n",
        "\n",
        "Dans cette étape, nous effectuons la détection de pose et le calcul d'angles pour une **POV (Point Of View)** unique. Nous utilisons le modèle **Yolo-NAS** pour prédire les poses à partir d'une vidéo, puis nous appliquons une fonction pour extraire les **keypoints** et calculer les angles entre certains points d'intérêt sur le squelette détecté. Cette approche nous permet d'obtenir des mesures d'angles spécifiques à partir d'un seul angle de vue.\n",
        "\n",
        "Le processus est le suivant :\n",
        "1. **Prédiction des poses** : Utilisation de Yolo-NAS pour détecter les poses dans chaque frame de la vidéo.\n",
        "2. **Extraction des keypoints** : Sélection des points d'intérêt pour le calcul d'angles en se basant sur la structure du squelette COCO.\n",
        "3. **Calcul des angles** : Application d'une formule géométrique pour déterminer l'angle entre trois points choisis, offrant ainsi une mesure de l'angle d'intérêt pour chaque frame.\n",
        "\n",
        "**Importance** : Cette cellule nous fournit une base solide pour comprendre comment les angles sont calculés à partir des données de pose estimées par le modèle pour une seule perspective. Cela est essentiel pour les étapes suivantes où nous envisageons d'intégrer des données de multiples POV.\n"
      ],
      "metadata": {
        "id": "NQv_ZVPSzwUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calcul d'angle avec une seule POV\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Initialisez une liste pour stocker les données des angles pour chaque frame\n",
        "angles_data = []\n",
        "processed_frames = []\n",
        "result = yolo_nas_pose.to('cuda').predict(\"video/front1.avi\", conf=.4)\n",
        "# Remplacez ceci par votre boucle existante pour traiter chaque frame\n",
        "for frame_index, image_prediction in enumerate(result._images_prediction_gen):\n",
        "    # Ici, nous extrayons les keypoints et calculons les angles au lieu de simplement traiter l'image\n",
        "    keypoints_coordinates = extract_keypoints_for_angles(image_prediction, confidence=0.55)\n",
        "\n",
        "    # Calcul des angles pour chaque groupe de keypoints d'intérêt\n",
        "    for angle_name, coords_group in keypoints_coordinates.items():\n",
        "        # Assurez-vous que nous avons exactement trois points (A, B, C)\n",
        "        if len(coords_group) == 3:\n",
        "            A, B, C = coords_group\n",
        "            angle = calculate_angle(A, B, C)\n",
        "            # Ajoutez le résultat dans la liste des données\n",
        "            angles_data.append({'Frame': frame_index, 'Angle Name': angle_name, 'Angle': angle})\n",
        "\n",
        "# Créez le DataFrame à partir de la liste des données\n",
        "df_angles = pd.DataFrame(angles_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSnpt8e8W1fv",
        "outputId": "a1dd7d75-17fb-452f-d605-01a529682c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-22 16:29:48] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
            "<ipython-input-6-61f1e69385e9>:18: RuntimeWarning: invalid value encountered in arccos\n",
            "  angle = np.arccos(cosine_angle)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calcul d'angle avec toutes les pov superposées (Useless mais codé)\n",
        "\n",
        "Cette cellule explore l'idée de superposer les données de pose de **multiples POV** et de sélectionner la meilleure frame basée sur le **score de confiance** pour chaque instant. Bien que théoriquement intéressante, cette approche s'est avérée peu pratique en raison des complications liées à la fusion des perspectives et à l'alignement des données dans un espace tridimensionnel complexe.\n",
        "\n",
        "**Raisonnement** :\n",
        "- **Superposition des données** : Tentative de combiner les informations de pose à partir de différentes angles de vue en une représentation unifiée.\n",
        "- **Sélection par score de confiance** : Choix de la frame avec le meilleur score de confiance pour chaque instant, sans tenir compte de la cohérence spatiale entre les différentes POV.\n",
        "\n",
        "**Conclusion** : Bien que réalisable, cette méthode introduit une complexité significative sans garantir une amélioration de la précision ou de la pertinence des mesures d'angle. Elle a donc été jugée moins utile pour notre objectif de mesure précise et cohérente des angles à travers différentes POV.\n"
      ],
      "metadata": {
        "id": "q9X4eIZjzypm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calcul d'angle avec toute les pov superposées (Useless mais codé)\n",
        "\n",
        "import os\n",
        "\n",
        "def process_and_select_best_frames_from_videos(video_folder, confidence_threshold=0.55):\n",
        "    video_files = [file for file in os.listdir(video_folder) if file.endswith('.mp4')]\n",
        "    best_frames_info = []  # Pour stocker le meilleur frame et son score pour chaque frame_index\n",
        "\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(video_folder, video_file)\n",
        "        result = yolo_nas_pose.to('cuda').predict(video_path, conf=confidence_threshold)\n",
        "\n",
        "        for frame_index, image_prediction in enumerate(result._images_prediction_gen):\n",
        "            # Obtenez les keypoints et calculez les angles pour la frame actuelle\n",
        "            keypoints_coordinates = extract_keypoints_for_angles(image_prediction, confidence=confidence_threshold)\n",
        "\n",
        "            # Obtenez le score de confiance global de la frame (supposant une logique pour l'obtenir)\n",
        "            frame_confidence_score = image_prediction.prediction.scores[0]  # Exemple hypothétique\n",
        "\n",
        "            if len(best_frames_info) <= frame_index:\n",
        "                # Si nous n'avons pas encore traité ce frame_index dans d'autres vidéos\n",
        "                best_frames_info.append({'frame': image_prediction, 'score': frame_confidence_score})\n",
        "            elif frame_confidence_score > best_frames_info[frame_index]['score']:\n",
        "                # Si le score de confiance actuel est meilleur que le meilleur précédent\n",
        "                best_frames_info[frame_index] = {'frame': image_prediction, 'score': frame_confidence_score}\n",
        "\n",
        "    # Après avoir examiné toutes les vidéos, dessinez les squelettes pour les meilleures frames sélectionnées\n",
        "    processed_frames = [process_single_image(frame_info['frame']) for frame_info in best_frames_info]\n",
        "\n",
        "    # Créez une vidéo à partir des meilleures frames sélectionnées\n",
        "    #create_video_from_frames(processed_frames, 'best_poses_video.mp4', fps=30)  # Assumer fps=30 pour l'exemple\n",
        "\n",
        "# Appliquez cette fonction au dossier contenant vos vidéos\n",
        "video_folder = \"video/zipedVideo\"\n",
        "process_and_select_best_frames_from_videos(video_folder)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c4ZZ-N-NwSpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf6190a-96c0-41e0-c44f-f09b69abeed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-17 15:54:42] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calcul d'angle moyen pondéré par le score de confiance avec toutes les pov\n",
        "\n",
        "Dans cette cellule, nous adoptons une approche raffinée pour intégrer les données de **multiples POV** en calculant un **angle moyen pondéré** basé sur les **scores de confiance**. Cette méthode tire parti des forces de chaque POV individuelle tout en atténuant les faiblesses potentielles liées à des angles de vue spécifiques.\n",
        "\n",
        "**Procédure** :\n",
        "1. **Calcul individuel des angles** : Pour chaque POV, nous calculons les angles et les scores de confiance associés.\n",
        "2. **Moyenne pondérée** : Les angles de chaque frame sont ensuite combinés en utilisant une moyenne pondérée par les scores de confiance, ce qui permet de privilégier les données les plus fiables.\n",
        "\n",
        "**Avantages** :\n",
        "- **Exploitation optimale des POV multiples** : Cette méthode permet de bénéficier de la diversité des points de vue sans les contraintes liées à leur superposition directe.\n",
        "- **Amélioration de la précision** : La moyenne pondérée augmente la fiabilité des mesures d'angle en donnant plus de poids aux estimations les plus confiantes.\n",
        "\n",
        "**Impact** : En fin de compte, cette approche nous offre une méthode robuste pour analyser les mouvements et postures à partir de vidéos capturées à partir de multiples angles, en assurant une intégration intelligente et efficace des données.\n"
      ],
      "metadata": {
        "id": "paRRkiS2z1Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calcul d'angle moyen pondéré par confidance score avec toute les pov\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def calculate_weighted_average_angles(video_folder, confidence_threshold=0.55):\n",
        "    video_files = [file for file in os.listdir(video_folder) if file.endswith('.avi')]\n",
        "    all_frames_data = []\n",
        "\n",
        "    # Étape 1: Calculer les angles pour chaque POV\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(video_folder, video_file)\n",
        "        result = yolo_nas_pose.to('cuda').predict(video_path, conf=confidence_threshold)\n",
        "        frames_data = []\n",
        "\n",
        "        for frame_index, image_prediction in enumerate(result._images_prediction_gen):\n",
        "            keypoints_coordinates = extract_keypoints_for_angles(image_prediction, confidence=confidence_threshold)\n",
        "            frame_data = {'Frame': frame_index}\n",
        "\n",
        "            for angle_name, coords_group in keypoints_coordinates.items():\n",
        "                if len(coords_group) == 3:\n",
        "                    A, B, C = coords_group\n",
        "                    angle = calculate_angle(A, B, C)\n",
        "                    frame_data[f'Angle {angle_name}'] = angle\n",
        "                    frame_data[f'Confidence {angle_name}'] = np.mean(image_prediction.prediction.scores)  # Exemple de calcul de confiance\n",
        "\n",
        "            frames_data.append(frame_data)\n",
        "\n",
        "        # Convertir en DataFrame et stocker dans la liste globale\n",
        "        df_video = pd.DataFrame(frames_data)\n",
        "        df_video['POV'] = video_file\n",
        "        all_frames_data.append(df_video)\n",
        "\n",
        "    # Étape 2: Fusionner tous les DataFrames de vidéos\n",
        "    df_all_videos = pd.concat(all_frames_data, ignore_index=True)\n",
        "\n",
        "    # Calculer la moyenne pondérée pour chaque frame et angle à travers toutes les vidéos\n",
        "    weighted_average_df = df_all_videos.groupby(['Frame', 'POV']).mean().reset_index()\n",
        "\n",
        "    return df_all_videos, weighted_average_df\n",
        "\n",
        "# Exemple d'utilisation\n",
        "video_folder = \"video/2\"\n",
        "df_weighted_angles,df_angles_all_videos = calculate_weighted_average_angles(video_folder)\n",
        "\n",
        "# Affichage des premières lignes du DataFrame final\n",
        "print(df_weighted_angles.head())\n"
      ],
      "metadata": {
        "id": "wiLlodRFx0lD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff67e9a8-4dad-416e-a7fa-6df11ba00f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-22 17:16:31] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
            "[2024-04-22 17:18:33] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
            "<ipython-input-15-1abc26a9f1cb>:18: RuntimeWarning: invalid value encountered in arccos\n",
            "  angle = np.arccos(cosine_angle)\n",
            "[2024-04-22 17:19:25] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_angles.head()\n",
        "df_angles.to_csv(\"anglesFront1.csv\")\n",
        "df_angles_all_videos.to_csv(\"allVid2Ok.csv\")\n",
        "df_weighted_angles.to_csv('anglesW2Ok.csv')"
      ],
      "metadata": {
        "id": "q9tuTOYZXTeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture fichier xsens pour sortir un df_angles_xsens"
      ],
      "metadata": {
        "id": "DC-U6mfjqkcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gdown\n",
        "\n",
        "def process_xsens_data(xsens_path, sheet_name, column_mapping):\n",
        "\n",
        "\n",
        "    # Lire les données du fichier Excel xSens\n",
        "    df_xsens = pd.read_excel(xsens_path, sheet_name=sheet_name)\n",
        "\n",
        "    # Sélectionner et renommer les colonnes en utilisant le dictionnaire de mappage\n",
        "    columns_of_interest = list(column_mapping.keys())\n",
        "    df_xsens_selected = df_xsens[columns_of_interest].rename(columns=column_mapping)\n",
        "\n",
        "    # Créer un DataFrame avec les angles renommés\n",
        "    df_angle_xsens = df_xsens_selected.rename(columns=lambda name: 'Angle ' + name)\n",
        "\n",
        "    return df_angle_xsens\n",
        "\n",
        "\n",
        "column_mapping = { # Manque des choses, c'est temporaire pour un test\n",
        "    'Frame': 'Frame',  # Assumer que le numéro de frame est correct\n",
        "    # Mappage des mesures de l'articulation de l'épaule\n",
        "    'Left Shoulder Flexion/Extension': 'Bras Gauche Flexion/Extension',\n",
        "    'Right Shoulder Flexion/Extension': 'Bras Droit Flexion/Extension',\n",
        "    # Mappage des mesures de l'articulation du coude\n",
        "    'Left Elbow Flexion/Extension': 'Coude Gauche Flexion/Extension',\n",
        "    'Right Elbow Flexion/Extension': 'Coude Droit Flexion/Extension',\n",
        "    # Mappage des mesures de l'articulation de la hanche pour la jambe\n",
        "    'Left Hip Flexion/Extension': 'Jambe Gauche Flexion/Extension',\n",
        "    'Right Hip Flexion/Extension': 'Jambe Droite Flexion/Extension',\n",
        "    # Mappage des mesures de l'articulation du genou\n",
        "    'Left Knee Flexion/Extension': 'Genou Gauche Flexion/Extension',\n",
        "    'Right Knee Flexion/Extension': 'Genou Droit Flexion/Extension',\n",
        "    # Mappage des mesures de l'articulation du poignet\n",
        "    'Left Wrist Flexion/Extension': 'Poignet Gauche Flexion/Extension',\n",
        "    'Right Wrist Flexion/Extension': 'Poignet Droit Flexion/Extension',\n",
        "}\n",
        "\n",
        "\n",
        "# Utiliser la fonction\n",
        "xsens_path = 'xsensData.xlsx'\n",
        "sheet_name = 'Joint Angles ZXY'  # Ou autre feuille du fichier Excel selon vos besoins\n",
        "df_angle_xsens = process_xsens_data(xsens_path, sheet_name, column_mapping)\n"
      ],
      "metadata": {
        "id": "JjcGTjEqqp5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_angle_xsens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoOntKyesVKI",
        "outputId": "7a1f1b0e-7a91-466d-e1b6-56af1774fa33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Angle Frame  Angle Bras Gauche Flexion/Extension  \\\n",
              "0               0                            19.834392   \n",
              "1               1                            19.793270   \n",
              "2               2                            19.752140   \n",
              "3               3                            19.709416   \n",
              "4               4                            19.661376   \n",
              "...           ...                                  ...   \n",
              "4037         4037                            23.637930   \n",
              "4038         4038                            23.621237   \n",
              "4039         4039                            23.600261   \n",
              "4040         4040                            23.576672   \n",
              "4041         4041                            23.553084   \n",
              "\n",
              "      Angle Bras Droit Flexion/Extension  \\\n",
              "0                              -2.398467   \n",
              "1                              -2.464427   \n",
              "2                              -2.530390   \n",
              "3                              -2.585937   \n",
              "4                              -2.624198   \n",
              "...                                  ...   \n",
              "4037                            5.585755   \n",
              "4038                            5.573018   \n",
              "4039                            5.561873   \n",
              "4040                            5.551231   \n",
              "4041                            5.540588   \n",
              "\n",
              "      Angle Coude Gauche Flexion/Extension  \\\n",
              "0                                13.001976   \n",
              "1                                12.910597   \n",
              "2                                12.819180   \n",
              "3                                12.747469   \n",
              "4                                12.702113   \n",
              "...                                    ...   \n",
              "4037                              6.933385   \n",
              "4038                              6.937896   \n",
              "4039                              6.939000   \n",
              "4040                              6.938520   \n",
              "4041                              6.938041   \n",
              "\n",
              "      Angle Coude Droit Flexion/Extension  \\\n",
              "0                               24.503302   \n",
              "1                               24.615320   \n",
              "2                               24.722739   \n",
              "3                               24.818088   \n",
              "4                               24.894425   \n",
              "...                                   ...   \n",
              "4037                            10.380064   \n",
              "4038                            10.386678   \n",
              "4039                            10.381776   \n",
              "4040                            10.370576   \n",
              "4041                            10.359376   \n",
              "\n",
              "      Angle Jambe Gauche Flexion/Extension  \\\n",
              "0                                 8.355053   \n",
              "1                                 8.259817   \n",
              "2                                 8.164611   \n",
              "3                                 8.077358   \n",
              "4                                 8.001356   \n",
              "...                                    ...   \n",
              "4037                              4.296421   \n",
              "4038                              4.294296   \n",
              "4039                              4.292516   \n",
              "4040                              4.290861   \n",
              "4041                              4.289206   \n",
              "\n",
              "      Angle Jambe Droite Flexion/Extension  \\\n",
              "0                                 5.295085   \n",
              "1                                 5.242339   \n",
              "2                                 5.189561   \n",
              "3                                 5.137920   \n",
              "4                                 5.088158   \n",
              "...                                    ...   \n",
              "4037                              1.546671   \n",
              "4038                              1.545041   \n",
              "4039                              1.544912   \n",
              "4040                              1.545499   \n",
              "4041                              1.546086   \n",
              "\n",
              "      Angle Genou Gauche Flexion/Extension  \\\n",
              "0                                 7.227706   \n",
              "1                                 7.174970   \n",
              "2                                 7.122247   \n",
              "3                                 7.077822   \n",
              "4                                 7.045603   \n",
              "...                                    ...   \n",
              "4037                              6.051620   \n",
              "4038                              6.049739   \n",
              "4039                              6.050735   \n",
              "4040                              6.053333   \n",
              "4041                              6.055930   \n",
              "\n",
              "      Angle Genou Droit Flexion/Extension  \\\n",
              "0                                4.974105   \n",
              "1                                4.984867   \n",
              "2                                4.995629   \n",
              "3                                5.005358   \n",
              "4                                5.015176   \n",
              "...                                   ...   \n",
              "4037                             3.261265   \n",
              "4038                             3.259248   \n",
              "4039                             3.261254   \n",
              "4040                             3.265330   \n",
              "4041                             3.269406   \n",
              "\n",
              "      Angle Poignet Gauche Flexion/Extension  \\\n",
              "0                                   7.397145   \n",
              "1                                   6.457907   \n",
              "2                                   5.519434   \n",
              "3                                   4.612105   \n",
              "4                                   3.742549   \n",
              "...                                      ...   \n",
              "4037                               10.302855   \n",
              "4038                               10.317083   \n",
              "4039                               10.329662   \n",
              "4040                               10.342551   \n",
              "4041                               10.355441   \n",
              "\n",
              "      Angle Poignet Droit Flexion/Extension  \n",
              "0                                 -0.147721  \n",
              "1                                 -0.199729  \n",
              "2                                 -0.255811  \n",
              "3                                 -0.545159  \n",
              "4                                 -1.195650  \n",
              "...                                     ...  \n",
              "4037                              -3.252249  \n",
              "4038                              -3.252079  \n",
              "4039                              -3.247059  \n",
              "4040                              -3.239248  \n",
              "4041                              -3.231440  \n",
              "\n",
              "[4042 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68e02b3e-a932-4a78-9c3f-3361c40af7d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Angle Frame</th>\n",
              "      <th>Angle Bras Gauche Flexion/Extension</th>\n",
              "      <th>Angle Bras Droit Flexion/Extension</th>\n",
              "      <th>Angle Coude Gauche Flexion/Extension</th>\n",
              "      <th>Angle Coude Droit Flexion/Extension</th>\n",
              "      <th>Angle Jambe Gauche Flexion/Extension</th>\n",
              "      <th>Angle Jambe Droite Flexion/Extension</th>\n",
              "      <th>Angle Genou Gauche Flexion/Extension</th>\n",
              "      <th>Angle Genou Droit Flexion/Extension</th>\n",
              "      <th>Angle Poignet Gauche Flexion/Extension</th>\n",
              "      <th>Angle Poignet Droit Flexion/Extension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>19.834392</td>\n",
              "      <td>-2.398467</td>\n",
              "      <td>13.001976</td>\n",
              "      <td>24.503302</td>\n",
              "      <td>8.355053</td>\n",
              "      <td>5.295085</td>\n",
              "      <td>7.227706</td>\n",
              "      <td>4.974105</td>\n",
              "      <td>7.397145</td>\n",
              "      <td>-0.147721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>19.793270</td>\n",
              "      <td>-2.464427</td>\n",
              "      <td>12.910597</td>\n",
              "      <td>24.615320</td>\n",
              "      <td>8.259817</td>\n",
              "      <td>5.242339</td>\n",
              "      <td>7.174970</td>\n",
              "      <td>4.984867</td>\n",
              "      <td>6.457907</td>\n",
              "      <td>-0.199729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>19.752140</td>\n",
              "      <td>-2.530390</td>\n",
              "      <td>12.819180</td>\n",
              "      <td>24.722739</td>\n",
              "      <td>8.164611</td>\n",
              "      <td>5.189561</td>\n",
              "      <td>7.122247</td>\n",
              "      <td>4.995629</td>\n",
              "      <td>5.519434</td>\n",
              "      <td>-0.255811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>19.709416</td>\n",
              "      <td>-2.585937</td>\n",
              "      <td>12.747469</td>\n",
              "      <td>24.818088</td>\n",
              "      <td>8.077358</td>\n",
              "      <td>5.137920</td>\n",
              "      <td>7.077822</td>\n",
              "      <td>5.005358</td>\n",
              "      <td>4.612105</td>\n",
              "      <td>-0.545159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>19.661376</td>\n",
              "      <td>-2.624198</td>\n",
              "      <td>12.702113</td>\n",
              "      <td>24.894425</td>\n",
              "      <td>8.001356</td>\n",
              "      <td>5.088158</td>\n",
              "      <td>7.045603</td>\n",
              "      <td>5.015176</td>\n",
              "      <td>3.742549</td>\n",
              "      <td>-1.195650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4037</th>\n",
              "      <td>4037</td>\n",
              "      <td>23.637930</td>\n",
              "      <td>5.585755</td>\n",
              "      <td>6.933385</td>\n",
              "      <td>10.380064</td>\n",
              "      <td>4.296421</td>\n",
              "      <td>1.546671</td>\n",
              "      <td>6.051620</td>\n",
              "      <td>3.261265</td>\n",
              "      <td>10.302855</td>\n",
              "      <td>-3.252249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4038</th>\n",
              "      <td>4038</td>\n",
              "      <td>23.621237</td>\n",
              "      <td>5.573018</td>\n",
              "      <td>6.937896</td>\n",
              "      <td>10.386678</td>\n",
              "      <td>4.294296</td>\n",
              "      <td>1.545041</td>\n",
              "      <td>6.049739</td>\n",
              "      <td>3.259248</td>\n",
              "      <td>10.317083</td>\n",
              "      <td>-3.252079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4039</th>\n",
              "      <td>4039</td>\n",
              "      <td>23.600261</td>\n",
              "      <td>5.561873</td>\n",
              "      <td>6.939000</td>\n",
              "      <td>10.381776</td>\n",
              "      <td>4.292516</td>\n",
              "      <td>1.544912</td>\n",
              "      <td>6.050735</td>\n",
              "      <td>3.261254</td>\n",
              "      <td>10.329662</td>\n",
              "      <td>-3.247059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4040</th>\n",
              "      <td>4040</td>\n",
              "      <td>23.576672</td>\n",
              "      <td>5.551231</td>\n",
              "      <td>6.938520</td>\n",
              "      <td>10.370576</td>\n",
              "      <td>4.290861</td>\n",
              "      <td>1.545499</td>\n",
              "      <td>6.053333</td>\n",
              "      <td>3.265330</td>\n",
              "      <td>10.342551</td>\n",
              "      <td>-3.239248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4041</th>\n",
              "      <td>4041</td>\n",
              "      <td>23.553084</td>\n",
              "      <td>5.540588</td>\n",
              "      <td>6.938041</td>\n",
              "      <td>10.359376</td>\n",
              "      <td>4.289206</td>\n",
              "      <td>1.546086</td>\n",
              "      <td>6.055930</td>\n",
              "      <td>3.269406</td>\n",
              "      <td>10.355441</td>\n",
              "      <td>-3.231440</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4042 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68e02b3e-a932-4a78-9c3f-3361c40af7d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68e02b3e-a932-4a78-9c3f-3361c40af7d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68e02b3e-a932-4a78-9c3f-3361c40af7d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ea76ba6-7f2a-46fc-9466-0dde66c2ca25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ea76ba6-7f2a-46fc-9466-0dde66c2ca25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ea76ba6-7f2a-46fc-9466-0dde66c2ca25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_angle_xsens",
              "summary": "{\n  \"name\": \"df_angle_xsens\",\n  \"rows\": 4042,\n  \"fields\": [\n    {\n      \"column\": \"Angle Frame\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1166,\n        \"min\": 0,\n        \"max\": 4041,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          4003,\n          149,\n          2025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Bras Gauche Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.612099939620144,\n        \"min\": -41.7933302671542,\n        \"max\": 129.485818698227,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          23.8520720304949,\n          20.1730644654862,\n          20.3103445401949\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Bras Droit Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.921074701974796,\n        \"min\": -69.5595846249841,\n        \"max\": 122.269799010882,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          5.47646753079063,\n          -2.1910382655934,\n          8.99655196433919\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Coude Gauche Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.624708154619,\n        \"min\": -8.8597755296013,\n        \"max\": 143.737203083919,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          6.90563876961562,\n          69.1993553814564,\n          -0.100389731586212\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Coude Droit Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34.93395292790922,\n        \"min\": 1.26663033467473,\n        \"max\": 150.298083945418,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          10.405981168136,\n          86.3857274000514,\n          11.3476885356835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Jambe Gauche Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.395683234570122,\n        \"min\": -2.20057192066431,\n        \"max\": 95.0465063484827,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          4.48343783302359,\n          6.83755579317801,\n          8.32605569754133\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Jambe Droite Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.736888844794775,\n        \"min\": -4.75175276154791,\n        \"max\": 85.937309149168,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          1.77634093756287,\n          3.95250715509854,\n          5.27893356391276\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Genou Gauche Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.331522395111502,\n        \"min\": 1.78932657708158,\n        \"max\": 119.951794784146,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          6.04408182913287,\n          6.89901622640001,\n          6.410498475274\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Genou Droit Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.95510427566676,\n        \"min\": 0.813112332199874,\n        \"max\": 113.651940396981,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          3.2907576886293,\n          4.74619987506366,\n          3.35103240358109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Poignet Gauche Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.132913337570955,\n        \"min\": -52.6773647297228,\n        \"max\": 76.9390280192354,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          10.0568967826963,\n          -19.2240027600566,\n          1.25361774784398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle Poignet Droit Flexion/Extension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.777549091954995,\n        \"min\": -46.1951638017126,\n        \"max\": 59.6488550834668,\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          -3.30903962459967,\n          -15.7074288169386,\n          -5.21814132377756\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction pour dessiner le Squelette"
      ],
      "metadata": {
        "id": "-3PY7HdIhlnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Sur toute les pov\n",
        "import os\n",
        "\n",
        "def process_all_videos(video_folder):\n",
        "    # Liste tous les fichiers dans le dossier\n",
        "    video_files = [file for file in os.listdir(video_folder) if file.endswith('.mp4')]\n",
        "\n",
        "    for video_file in video_files:\n",
        "        # Préparez une liste pour collecter les frames traitées\n",
        "        processed_frames = []\n",
        "\n",
        "        # Chemin complet vers la vidéo\n",
        "        video_path = os.path.join(video_folder, video_file)\n",
        "\n",
        "        # Prédiction des poses pour la vidéo actuelle\n",
        "        result = yolo_nas_pose.to('cuda').predict(video_path, conf=.4)\n",
        "\n",
        "        # Itérer sur chaque prédiction d'image dans le générateur\n",
        "        for image_prediction in result._images_prediction_gen:\n",
        "            # Appliquez le traitement nécessaire pour chaque image\n",
        "            # En utilisant une fonction `process_single_image` pour dessiner les squelettes\n",
        "            processed_image = process_single_image(image_prediction)\n",
        "            processed_frames.append(processed_image)\n",
        "\n",
        "        # Après avoir collecté toutes les frames traitées, créez une vidéo\n",
        "        # Le nom de la vidéo de sortie est basé sur le nom du fichier d'entrée\n",
        "        output_video_path = os.path.join(video_folder, f\"skeleton_{video_file}\")\n",
        "        create_video_from_frames(processed_frames, output_video_path, fps=result.fps)\n",
        "\n",
        "# Utilisez cette fonction en spécifiant le chemin du dossier contenant vos vidéos\n",
        "video_folder = \"video/zipedVideo\"\n",
        "process_all_videos(video_folder)\n"
      ],
      "metadata": {
        "id": "dcdP05X4tJBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2a0581b-ff55-40dc-e153-da066dcfb57d",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-18 18:56:30] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# URL du fichier ZIP sur Google Drive\n",
        "url = 'https://drive.google.com/uc?id=1ngVS0Qfn5NqR1yvc64lP8BE-96Dg3Lvi'\n",
        "\n",
        "output_zip_path = '/content/video_archive.zip'\n",
        "\n",
        "# Dossier cible pour extraire le contenu du fichier ZIP\n",
        "extract_to_folder = '/content/video2'\n",
        "\n",
        "# Créez le dossier s'il n'existe pas\n",
        "if not os.path.exists(extract_to_folder):\n",
        "    os.makedirs(extract_to_folder)\n",
        "\n",
        "# Téléchargez le fichier ZIP\n",
        "gdown.download(url, output_zip_path, quiet=False)\n",
        "\n",
        "# Décompressez le fichier ZIP\n",
        "with zipfile.ZipFile(output_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_folder)\n",
        "\n",
        "# Supprimez le fichier ZIP si vous n'en avez plus besoin\n",
        "os.remove(output_zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9vZ8qNZXlA-",
        "outputId": "8986f428-02c9-45bb-883c-216145193363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ngVS0Qfn5NqR1yvc64lP8BE-96Dg3Lvi\n",
            "From (redirected): https://drive.google.com/uc?id=1ngVS0Qfn5NqR1yvc64lP8BE-96Dg3Lvi&confirm=t&uuid=c543a8cb-8243-4951-a79f-e6445021e75c\n",
            "To: /content/video_archive.zip\n",
            "100%|██████████| 42.9M/42.9M [00:00<00:00, 51.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sur une seule pov\n",
        "\n",
        "\n",
        "# Préparez une liste pour collecter les frames traitées\n",
        "\n",
        "processed_frames = []\n",
        "result = yolo_nas_pose.to('cuda').predict(\"video2/side1.mp4\", conf=.4)\n",
        "# Itérez sur chaque prédiction d'image dans le générateur\n",
        "for image_prediction in result._images_prediction_gen:\n",
        "    # Appliquez le traitement nécessaire pour chaque image\n",
        "    # Par exemple, en utilisant une fonction fictive `process_single_image` que vous devez définir ou adapter\n",
        "    processed_image = process_single_image(image_prediction)\n",
        "    processed_frames.append(processed_image)\n",
        "\n",
        "\n",
        "# Après avoir collecté toutes les frames traitées, créez une vidéo\n",
        "# Assurez-vous d'avoir une fonction `create_video_from_frames` qui prend la liste des frames et le chemin de sortie\n",
        "create_video_from_frames(processed_frames, 'side1Skeleton.mp4', fps=result.fps)"
      ],
      "metadata": {
        "id": "uvIKqebIuhK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4a3054-74c5-4b78-f429-823cb6752718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-22 19:58:17] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PHwVb_MUucDr"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "DC-U6mfjqkcR",
        "-3PY7HdIhlnV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}